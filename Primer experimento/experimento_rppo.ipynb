{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "727a4565",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized trainable embeddings for 50 objects\n",
      "Objects: ['airplane', 'alarmclock', 'apple', 'banana', 'binoculars', 'bowl', 'camera', 'cubelarge', 'cubemedium', 'cubesmall', 'cup', 'cylinderlarge', 'cylindermedium', 'cylindersmall', 'doorknob', 'duck', 'elephant', 'eyeglasses', 'flashlight', 'flute', 'fryingpan', 'gamecontroller', 'hammer', 'hand', 'headphones', 'knife', 'lightbulb', 'mouse', 'mug', 'phone', 'piggybank', 'pyramidlarge', 'pyramidmedium', 'pyramidsmall', 'scissors', 'spherelarge', 'spheremedium', 'spheresmall', 'stamp', 'stanfordbunny', 'stapler', 'toothbrush', 'toothpaste', 'toruslarge', 'torusmedium', 'torussmall', 'train', 'watch', 'waterbottle', 'wineglass']\n",
      "torussmall_inspect_1_s9_scene.xml\n",
      "torussmall_inspect_1\n",
      "airplane_fly_1_s6_scene.xml\n",
      "airplane_fly_1\n",
      "waterbottle_pour_2_s3_scene.xml\n",
      "waterbottle_pour_2\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "Model incompatible with new observation space. Starting fresh training.\n",
      "Reason: Observation spaces do not match: Box(-inf, inf, (39,), float32) != Box(-inf, inf, (55,), float32)\n",
      "Starting training from scratch with trainable object embeddings\n",
      "Using cuda device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "Embedding manager transferred to policy for training\n",
      "Starting phase 1: {'timesteps': 100000, 'max_hand_height': 0.3, 'objects': 'simple'}\n",
      "piggybank_pass_1_s7_scene.xml\n",
      "piggybank_pass_1\n",
      "Logging to ./rppo_tensorboard_embeddings/RecurrentPPO_0\n",
      "waterbottle_lift_s8_scene.xml\n",
      "waterbottle_lift\n",
      "[waterbottle] FAILURE - Contact ratio: 0.00\n",
      "cubemedium_pass_1_s9_scene.xml\n",
      "cubemedium_pass_1\n",
      "[cubemedium] FAILURE - Contact ratio: 0.00\n",
      "knife_lift_s1_scene.xml\n",
      "knife_lift\n",
      "[knife] FAILURE - Contact ratio: 0.00\n",
      "toothbrush_pass_1_s8_scene.xml\n",
      "toothbrush_pass_1\n",
      "[toothbrush] FAILURE - Contact ratio: 0.00\n",
      "cylindersmall_lift_s8_scene.xml\n",
      "cylindersmall_lift\n",
      "[cylindersmall] FAILURE - Contact ratio: 0.00\n",
      "camera_takepicture_1_s6_scene.xml\n",
      "camera_takepicture_1\n",
      "[camera] FAILURE - Contact ratio: 0.01\n",
      "stanfordbunny_pass_1_s8_scene.xml\n",
      "stanfordbunny_pass_1\n",
      "train_lift_s4_scene.xml\n",
      "train_lift\n",
      "[train] FAILURE - Contact ratio: 0.00\n",
      "apple_lift_s9_scene.xml\n",
      "apple_lift\n",
      "[apple] FAILURE - Contact ratio: 0.00\n",
      "cup_pass_1_s7_scene.xml\n",
      "cup_pass_1\n",
      "[cup] FAILURE - Contact ratio: 0.00\n",
      "cubemedium_inspect_1_s2_scene.xml\n",
      "cubemedium_inspect_1\n",
      "[cubemedium] FAILURE - Contact ratio: 0.00\n",
      "elephant_inspect_1_s5_scene.xml\n",
      "elephant_inspect_1\n",
      "[elephant] FAILURE - Contact ratio: 0.00\n",
      "cylindermedium_lift_s1_scene.xml\n",
      "cylindermedium_lift\n",
      "----------------------------------\n",
      "| eval/              |           |\n",
      "|    mean_reward     | -9.86e+04 |\n",
      "|    std_reward      | 1.97e+05  |\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 130       |\n",
      "|    ep_rew_mean     | -10.1     |\n",
      "| time/              |           |\n",
      "|    fps             | 7         |\n",
      "|    iterations      | 1         |\n",
      "|    time_elapsed    | 269       |\n",
      "|    total_timesteps | 2048      |\n",
      "----------------------------------\n",
      "bowl_lift_s8_scene.xml\n",
      "bowl_lift\n",
      "[bowl] FAILURE - Contact ratio: 0.00\n",
      "knife_pass_1_s10_scene.xml\n",
      "knife_pass_1\n",
      "[knife] FAILURE - Contact ratio: 0.00\n",
      "cup_drink_1_s4_scene.xml\n",
      "cup_drink_1\n",
      "[cup] FAILURE - Contact ratio: 0.00\n",
      "knife_chop_1_s10_scene.xml\n",
      "knife_chop_1\n",
      "[knife] FAILURE - Contact ratio: 0.00\n",
      "cylindersmall_lift_s1_scene.xml\n",
      "cylindersmall_lift\n",
      "[cylindersmall] FAILURE - Contact ratio: 0.00\n",
      "train_play_1_s8_scene.xml\n",
      "train_play_1\n",
      "[train] FAILURE - Contact ratio: 0.00\n",
      "knife_pass_1_s9_scene.xml\n",
      "knife_pass_1\n",
      "[knife] FAILURE - Contact ratio: 0.00\n",
      "cup_pour_1_s3_scene.xml\n",
      "cup_pour_1\n",
      "[cup] FAILURE - Contact ratio: 0.00\n",
      "train_play_1_s7_scene.xml\n",
      "train_play_1\n",
      "[train] FAILURE - Contact ratio: 0.01\n",
      "cylindersmall_inspect_1_s8_scene.xml\n",
      "cylindersmall_inspect_1\n",
      "knife_peel_1_s8_scene.xml\n",
      "knife_peel_1\n",
      "[knife] FAILURE - Contact ratio: 0.00\n",
      "elephant_inspect_1_s1_scene.xml\n",
      "elephant_inspect_1\n",
      "[elephant] FAILURE - Contact ratio: 0.01\n",
      "toothbrush_lift_s1_scene.xml\n",
      "toothbrush_lift\n",
      "[toothbrush] FAILURE - Contact ratio: 0.00\n",
      "toothbrush_brush_1_s8_scene.xml\n",
      "toothbrush_brush_1\n",
      "[toothbrush] FAILURE - Contact ratio: 0.00\n",
      "bowl_drink_2_s9_scene.xml\n",
      "bowl_drink_2\n",
      "[bowl] FAILURE - Contact ratio: 0.00\n",
      "cylindersmall_pass_1_s9_scene.xml\n",
      "cylindersmall_pass_1\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_reward          | -9.41        |\n",
      "|    std_reward           | 0.254        |\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 130          |\n",
      "|    ep_rew_mean          | -10.2        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 11           |\n",
      "|    iterations           | 2            |\n",
      "|    time_elapsed         | 348          |\n",
      "|    total_timesteps      | 4096         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0055390964 |\n",
      "|    clip_fraction        | 0.0365       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    clip_range_vf        | 0.2          |\n",
      "|    entropy_loss         | -25.6        |\n",
      "|    explained_variance   | 0.000188     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 9.66         |\n",
      "|    n_updates            | 10           |\n",
      "|    policy_gradient_loss | -0.0015      |\n",
      "|    std                  | 1            |\n",
      "|    value_loss           | 84.4         |\n",
      "------------------------------------------\n",
      "apple_eat_1_s8_scene.xml\n",
      "apple_eat_1\n",
      "[apple] FAILURE - Contact ratio: 0.00\n",
      "toothbrush_pass_1_s4_scene.xml\n",
      "toothbrush_pass_1\n",
      "[toothbrush] FAILURE - Contact ratio: 0.00\n",
      "knife_chop_1_s10_scene.xml\n",
      "knife_chop_1\n",
      "[knife] FAILURE - Contact ratio: 0.00\n",
      "cup_lift_s4_scene.xml\n",
      "cup_lift\n",
      "[cup] FAILURE - Contact ratio: 0.00\n",
      "cup_pass_1_s6_scene.xml\n",
      "cup_pass_1\n",
      "[cup] FAILURE - Contact ratio: 0.00\n",
      "apple_eat_1_s3_scene.xml\n",
      "apple_eat_1\n",
      "[apple] FAILURE - Contact ratio: 0.00\n",
      "bowl_drink_1_s9_scene.xml\n",
      "bowl_drink_1\n",
      "[bowl] FAILURE - Contact ratio: 0.00\n",
      "toothbrush_pass_1_s7_scene.xml\n",
      "toothbrush_pass_1\n",
      "[toothbrush] FAILURE - Contact ratio: 0.00\n",
      "cup_pass_1_s9_scene.xml\n",
      "cup_pass_1\n",
      "[cup] FAILURE - Contact ratio: 0.03\n",
      "cylindersmall_lift_s8_scene.xml\n",
      "cylindersmall_lift\n",
      "camera_takepicture_1_s3_scene.xml\n",
      "camera_takepicture_1\n",
      "[camera] FAILURE - Contact ratio: 0.00\n",
      "knife_chop_1_s10_scene.xml\n",
      "knife_chop_1\n",
      "[knife] FAILURE - Contact ratio: 0.00\n",
      "camera_browse_1_s10_scene.xml\n",
      "camera_browse_1\n",
      "[camera] FAILURE - Contact ratio: 0.00\n",
      "apple_eat_1_s6_scene.xml\n",
      "apple_eat_1\n",
      "[apple] FAILURE - Contact ratio: 0.00\n",
      "toothbrush_lift_s1_scene.xml\n",
      "toothbrush_lift\n",
      "[toothbrush] FAILURE - Contact ratio: 0.00\n",
      "toothbrush_brush_1_s3_scene.xml\n",
      "toothbrush_brush_1\n",
      "[toothbrush] FAILURE - Contact ratio: 0.00\n",
      "bowl_lift_s9_scene.xml\n",
      "bowl_lift\n",
      "-----------------------------------------\n",
      "| embeddings/             |             |\n",
      "|    dim_0_mean           | 0.22720008  |\n",
      "|    dim_0_std            | 0.33652073  |\n",
      "|    dim_1_mean           | 0.16976628  |\n",
      "|    dim_1_std            | 0.31452113  |\n",
      "|    dim_2_mean           | 0.07822708  |\n",
      "|    dim_2_std            | 0.24319409  |\n",
      "|    dim_3_mean           | 0.055843942 |\n",
      "|    dim_3_std            | 0.24363105  |\n",
      "|    max_norm             | 1.0583005   |\n",
      "|    mean_norm            | 0.67657787  |\n",
      "|    min_norm             | 0.24225417  |\n",
      "|    std_norm             | 0.28642362  |\n",
      "| eval/                   |             |\n",
      "|    mean_reward          | -9.59       |\n",
      "|    std_reward           | 0.521       |\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 130         |\n",
      "|    ep_rew_mean          | -9.92       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 16          |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 362         |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.00514076  |\n",
      "|    clip_fraction        | 0.0335      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    clip_range_vf        | 0.2         |\n",
      "|    entropy_loss         | -25.6       |\n",
      "|    explained_variance   | 0.117       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 73.4        |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.00433    |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 45.4        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[bowl] FAILURE - Contact ratio: 0.01\n",
      "bowl_pass_1_s5_scene.xml\n",
      "bowl_pass_1\n",
      "[bowl] FAILURE - Contact ratio: 0.00\n",
      "toothbrush_brush_1_s8_scene.xml\n",
      "toothbrush_brush_1\n",
      "[toothbrush] FAILURE - Contact ratio: 0.00\n",
      "camera_browse_1_s9_scene.xml\n",
      "camera_browse_1\n",
      "[camera] FAILURE - Contact ratio: 0.00\n",
      "knife_chop_1_s7_scene.xml\n",
      "knife_chop_1\n",
      "[knife] FAILURE - Contact ratio: 0.00\n",
      "cylindersmall_inspect_1_s5_scene.xml\n",
      "cylindersmall_inspect_1\n",
      "apple_eat_1_s1_scene.xml\n",
      "apple_eat_1\n",
      "[apple] FAILURE - Contact ratio: 0.00\n",
      "bowl_drink_1_s7_scene.xml\n",
      "bowl_drink_1\n",
      "[bowl] FAILURE - Contact ratio: 0.03\n",
      "apple_eat_1_s4_scene.xml\n",
      "apple_eat_1\n",
      "[apple] FAILURE - Contact ratio: 0.00\n",
      "train_pass_1_s2_scene.xml\n",
      "train_pass_1\n",
      "[train] FAILURE - Contact ratio: 0.00\n",
      "apple_pass_1_s3_scene.xml\n",
      "apple_pass_1\n",
      "[apple] FAILURE - Contact ratio: 0.00\n",
      "train_pass_1_s4_scene.xml\n",
      "train_pass_1\n",
      "[train] FAILURE - Contact ratio: 0.00\n",
      "cylindersmall_inspect_1_s10_scene.xml\n",
      "cylindersmall_inspect_1\n",
      "cylindersmall_pass_1_s5_scene.xml\n",
      "cylindersmall_pass_1\n",
      "[cylindersmall] FAILURE - Contact ratio: 0.00\n",
      "apple_pass_1_s8_scene.xml\n",
      "apple_pass_1\n",
      "[apple] FAILURE - Contact ratio: 0.00\n",
      "camera_pass_1_s10_scene.xml\n",
      "camera_pass_1\n",
      "[camera] FAILURE - Contact ratio: 0.00\n",
      "toothbrush_pass_1_s3_scene.xml\n",
      "toothbrush_pass_1\n",
      "[toothbrush] FAILURE - Contact ratio: 0.00\n",
      "apple_lift_s9_scene.xml\n",
      "apple_lift\n",
      "[apple] FAILURE - Contact ratio: 0.00\n",
      "camera_offhand_1_s3_scene.xml\n",
      "camera_offhand_1\n",
      "[camera] FAILURE - Contact ratio: 0.00\n",
      "cylindersmall_inspect_1_s5_scene.xml\n",
      "cylindersmall_inspect_1\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_reward          | -9.87e+04   |\n",
      "|    std_reward           | 1.97e+05    |\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 129         |\n",
      "|    ep_rew_mean          | -9.88       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 18          |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 445         |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005044898 |\n",
      "|    clip_fraction        | 0.0222      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    clip_range_vf        | 0.2         |\n",
      "|    entropy_loss         | -25.7       |\n",
      "|    explained_variance   | 0.198       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 17.9        |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.00258    |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 36.4        |\n",
      "-----------------------------------------\n",
      "toothbrush_brush_1_s8_scene.xml\n",
      "toothbrush_brush_1\n",
      "[toothbrush] FAILURE - Contact ratio: 0.00\n",
      "toothbrush_brush_1_s3_scene.xml\n",
      "toothbrush_brush_1\n",
      "[toothbrush] FAILURE - Contact ratio: 0.00\n",
      "knife_pass_1_s8_scene.xml\n",
      "knife_pass_1\n",
      "[knife] FAILURE - Contact ratio: 0.00\n",
      "knife_pass_1_s9_scene.xml\n",
      "knife_pass_1\n",
      "[knife] FAILURE - Contact ratio: 0.00\n",
      "train_lift_s7_scene.xml\n",
      "train_lift\n",
      "[train] FAILURE - Contact ratio: 0.00\n",
      "apple_offhand_1_s1_scene.xml\n",
      "apple_offhand_1\n",
      "[apple] FAILURE - Contact ratio: 0.00\n",
      "apple_eat_1_s9_scene.xml\n",
      "apple_eat_1\n",
      "[apple] FAILURE - Contact ratio: 0.00\n",
      "apple_offhand_1_Retake_s6_scene.xml\n",
      "apple_offhand_1_Retake\n",
      "[apple] FAILURE - Contact ratio: 0.00\n",
      "cylindersmall_pass_1_s6_scene.xml\n",
      "cylindersmall_pass_1\n",
      "cylindersmall_lift_s4_scene.xml\n",
      "cylindersmall_lift\n",
      "[cylindersmall] FAILURE - Contact ratio: 0.00\n",
      "cylindersmall_inspect_1_s7_scene.xml\n",
      "cylindersmall_inspect_1\n",
      "[cylindersmall] FAILURE - Contact ratio: 0.00\n",
      "apple_eat_1_s6_scene.xml\n",
      "apple_eat_1\n",
      "[apple] FAILURE - Contact ratio: 0.00\n",
      "camera_offhand_1_s8_scene.xml\n",
      "camera_offhand_1\n",
      "[camera] FAILURE - Contact ratio: 0.00\n",
      "train_play_1_s10_scene.xml\n",
      "train_play_1\n",
      "[train] FAILURE - Contact ratio: 0.00\n",
      "apple_pass_1_s8_scene.xml\n",
      "apple_pass_1\n",
      "[apple] FAILURE - Contact ratio: 0.00\n",
      "apple_eat_1_s1_scene.xml\n",
      "apple_eat_1\n",
      "-----------------------------------------\n",
      "| embeddings/             |             |\n",
      "|    dim_0_mean           | 0.22720008  |\n",
      "|    dim_0_std            | 0.33652073  |\n",
      "|    dim_1_mean           | 0.16976628  |\n",
      "|    dim_1_std            | 0.31452113  |\n",
      "|    dim_2_mean           | 0.07822708  |\n",
      "|    dim_2_std            | 0.24319409  |\n",
      "|    dim_3_mean           | 0.055843942 |\n",
      "|    dim_3_std            | 0.24363105  |\n",
      "|    max_norm             | 1.0583005   |\n",
      "|    mean_norm            | 0.67657787  |\n",
      "|    min_norm             | 0.24225417  |\n",
      "|    std_norm             | 0.28642362  |\n",
      "| eval/                   |             |\n",
      "|    mean_reward          | -1.97e+05   |\n",
      "|    std_reward           | 2.41e+05    |\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 130         |\n",
      "|    ep_rew_mean          | -9.86       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 17          |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 592         |\n",
      "|    total_timesteps      | 10240       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008864924 |\n",
      "|    clip_fraction        | 0.111       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    clip_range_vf        | 0.2         |\n",
      "|    entropy_loss         | -25.7       |\n",
      "|    explained_variance   | -0.116      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 4.26        |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.0109     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 88.8        |\n",
      "-----------------------------------------\n",
      "[apple] FAILURE - Contact ratio: 0.00\n",
      "apple_pass_1_s1_scene.xml\n",
      "apple_pass_1\n",
      "[apple] FAILURE - Contact ratio: 0.00\n",
      "camera_browse_1_s10_scene.xml\n",
      "camera_browse_1\n",
      "[camera] FAILURE - Contact ratio: 0.00\n",
      "cylindersmall_pass_1_s10_scene.xml\n",
      "cylindersmall_pass_1\n",
      "knife_peel_1_s6_scene.xml\n",
      "knife_peel_1\n",
      "[knife] FAILURE - Contact ratio: 0.00\n",
      "cylindersmall_offhand_1_s1_scene.xml\n",
      "cylindersmall_offhand_1\n",
      "[cylindersmall] FAILURE - Contact ratio: 0.00\n",
      "cylindersmall_pass_1_s4_scene.xml\n",
      "cylindersmall_pass_1\n",
      "[cylindersmall] FAILURE - Contact ratio: 0.00\n",
      "camera_takepicture_3_s8_scene.xml\n",
      "camera_takepicture_3\n",
      "[camera] FAILURE - Contact ratio: 0.00\n",
      "apple_pass_1_s5_scene.xml\n",
      "apple_pass_1\n",
      "[apple] FAILURE - Contact ratio: 0.00\n",
      "camera_pass_1_s2_scene.xml\n",
      "camera_pass_1\n",
      "[camera] FAILURE - Contact ratio: 0.00\n",
      "cylindersmall_inspect_1_s8_scene.xml\n",
      "cylindersmall_inspect_1\n",
      "cylindersmall_lift_s8_scene.xml\n",
      "cylindersmall_lift\n",
      "[cylindersmall] FAILURE - Contact ratio: 0.00\n",
      "knife_peel_1_s8_scene.xml\n",
      "knife_peel_1\n",
      "[knife] FAILURE - Contact ratio: 0.00\n",
      "toothbrush_pass_1_s7_scene.xml\n",
      "toothbrush_pass_1\n",
      "[toothbrush] FAILURE - Contact ratio: 0.00\n",
      "toothbrush_brush_1_s8_scene.xml\n",
      "toothbrush_brush_1\n",
      "[toothbrush] FAILURE - Contact ratio: 0.00\n",
      "apple_offhand_1_Retake_s6_scene.xml\n",
      "apple_offhand_1_Retake\n",
      "[apple] FAILURE - Contact ratio: 0.01\n",
      "apple_pass_1_s3_scene.xml\n",
      "apple_pass_1\n",
      "[apple] FAILURE - Contact ratio: 0.00\n",
      "train_lift_s7_scene.xml\n",
      "train_lift\n",
      "[train] FAILURE - Contact ratio: 0.00\n",
      "apple_lift_s4_scene.xml\n",
      "apple_lift\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_reward          | -9.86e+04   |\n",
      "|    std_reward           | 1.97e+05    |\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 129         |\n",
      "|    ep_rew_mean          | -9.82       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 15          |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 809         |\n",
      "|    total_timesteps      | 12288       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008743184 |\n",
      "|    clip_fraction        | 0.0838      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    clip_range_vf        | 0.2         |\n",
      "|    entropy_loss         | -25.8       |\n",
      "|    explained_variance   | -0.262      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 744         |\n",
      "|    n_updates            | 50          |\n",
      "|    policy_gradient_loss | -0.00615    |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 499         |\n",
      "-----------------------------------------\n",
      "[apple] FAILURE - Contact ratio: 0.00\n",
      "train_pass_1_s2_scene.xml\n",
      "train_pass_1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[train] FAILURE - Contact ratio: 0.00\n",
      "train_play_1_s2_scene.xml\n",
      "train_play_1\n",
      "[train] FAILURE - Contact ratio: 0.00\n",
      "camera_lift_s4_scene.xml\n",
      "camera_lift\n",
      "[camera] FAILURE - Contact ratio: 0.00\n",
      "train_offhand_1_s1_scene.xml\n",
      "train_offhand_1\n",
      "[train] FAILURE - Contact ratio: 0.00\n",
      "knife_peel_1_s6_scene.xml\n",
      "knife_peel_1\n",
      "cylindersmall_lift_s8_scene.xml\n",
      "cylindersmall_lift\n",
      "[cylindersmall] FAILURE - Contact ratio: 0.00\n",
      "cylindersmall_pass_1_s6_scene.xml\n",
      "cylindersmall_pass_1\n",
      "[cylindersmall] FAILURE - Contact ratio: 0.00\n",
      "train_pass_1_s3_scene.xml\n",
      "train_pass_1\n",
      "[train] FAILURE - Contact ratio: 0.00\n",
      "cylindersmall_pass_1_s5_scene.xml\n",
      "cylindersmall_pass_1\n",
      "[cylindersmall] FAILURE - Contact ratio: 0.00\n",
      "toothbrush_brush_1_s5_scene.xml\n",
      "toothbrush_brush_1\n",
      "[toothbrush] FAILURE - Contact ratio: 0.00\n",
      "toothbrush_brush_1_s8_scene.xml\n",
      "toothbrush_brush_1\n",
      "[toothbrush] FAILURE - Contact ratio: 0.00\n",
      "camera_takepicture_2_s6_scene.xml\n",
      "camera_takepicture_2\n",
      "[camera] FAILURE - Contact ratio: 0.00\n",
      "train_pass_1_s2_scene.xml\n",
      "train_pass_1\n",
      "[train] FAILURE - Contact ratio: 0.00\n",
      "toothbrush_pass_1_s3_scene.xml\n",
      "toothbrush_pass_1\n",
      "[toothbrush] FAILURE - Contact ratio: 0.00\n",
      "apple_pass_1_s3_scene.xml\n",
      "apple_pass_1\n",
      "[apple] FAILURE - Contact ratio: 0.00\n",
      "toothbrush_brush_1_s5_scene.xml\n",
      "toothbrush_brush_1\n",
      "[toothbrush] FAILURE - Contact ratio: 0.00\n",
      "knife_lift_s3_scene.xml\n",
      "knife_lift\n",
      "[knife] FAILURE - Contact ratio: 0.00\n",
      "camera_lift_s2_scene.xml\n",
      "camera_lift\n",
      "cylindersmall_pass_1_s6_scene.xml\n",
      "cylindersmall_pass_1\n",
      "[cylindersmall] FAILURE - Contact ratio: 0.00\n",
      "apple_pass_1_s1_scene.xml\n",
      "apple_pass_1\n",
      "[apple] FAILURE - Contact ratio: 0.00\n",
      "train_lift_s3_scene.xml\n",
      "train_lift\n",
      "[train] FAILURE - Contact ratio: 0.00\n",
      "apple_pass_1_s4_scene.xml\n",
      "apple_pass_1\n",
      "[apple] FAILURE - Contact ratio: 0.00\n",
      "cylindersmall_pass_1_s7_scene.xml\n",
      "cylindersmall_pass_1\n",
      "[cylindersmall] FAILURE - Contact ratio: 0.00\n",
      "camera_offhand_1_s1_scene.xml\n",
      "camera_offhand_1\n",
      "[camera] FAILURE - Contact ratio: 0.00\n",
      "toothbrush_pass_1_s9_scene.xml\n",
      "toothbrush_pass_1\n",
      "[toothbrush] FAILURE - Contact ratio: 0.00\n",
      "knife_lift_s1_scene.xml\n",
      "knife_lift\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_reward          | -1.97e+05  |\n",
      "|    std_reward           | 2.42e+05   |\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 128        |\n",
      "|    ep_rew_mean          | -9.75      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 12         |\n",
      "|    iterations           | 7          |\n",
      "|    time_elapsed         | 1160       |\n",
      "|    total_timesteps      | 14336      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00545616 |\n",
      "|    clip_fraction        | 0.0719     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    clip_range_vf        | 0.2        |\n",
      "|    entropy_loss         | -25.8      |\n",
      "|    explained_variance   | -0.109     |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 202        |\n",
      "|    n_updates            | 60         |\n",
      "|    policy_gradient_loss | -0.00607   |\n",
      "|    std                  | 1.02       |\n",
      "|    value_loss           | 166        |\n",
      "----------------------------------------\n",
      "[knife] FAILURE - Contact ratio: 0.00\n",
      "cylindersmall_inspect_1_s1_scene.xml\n",
      "cylindersmall_inspect_1\n",
      "train_play_1_s5_scene.xml\n",
      "train_play_1\n",
      "[train] FAILURE - Contact ratio: 0.00\n",
      "cylindersmall_inspect_1_s9_scene.xml\n",
      "cylindersmall_inspect_1\n",
      "[cylindersmall] FAILURE - Contact ratio: 0.00\n",
      "cylindersmall_pass_1_s1_scene.xml\n",
      "cylindersmall_pass_1\n",
      "[cylindersmall] FAILURE - Contact ratio: 0.00\n",
      "camera_takepicture_1_s1_scene.xml\n",
      "camera_takepicture_1\n",
      "[camera] FAILURE - Contact ratio: 0.00\n",
      "knife_peel_1_s10_scene.xml\n",
      "knife_peel_1\n",
      "[knife] FAILURE - Contact ratio: 0.00\n",
      "train_play_1_s2_scene.xml\n",
      "train_play_1\n",
      "[train] FAILURE - Contact ratio: 0.00\n",
      "toothbrush_pass_1_s4_scene.xml\n",
      "toothbrush_pass_1\n",
      "[toothbrush] FAILURE - Contact ratio: 0.00\n",
      "camera_offhand_1_s8_scene.xml\n",
      "camera_offhand_1\n",
      "[camera] FAILURE - Contact ratio: 0.00\n",
      "train_play_1_s8_scene.xml\n",
      "train_play_1\n",
      "[train] FAILURE - Contact ratio: 0.00\n",
      "cylindersmall_pass_1_s2_scene.xml\n",
      "cylindersmall_pass_1\n",
      "toothbrush_brush_1_s8_scene.xml\n",
      "toothbrush_brush_1\n",
      "[toothbrush] FAILURE - Contact ratio: 0.00\n",
      "camera_takepicture_1_s1_scene.xml\n",
      "camera_takepicture_1\n",
      "[camera] FAILURE - Contact ratio: 0.00\n",
      "toothbrush_pass_1_s7_scene.xml\n",
      "toothbrush_pass_1\n",
      "[toothbrush] FAILURE - Contact ratio: 0.00\n",
      "camera_browse_1_s7_scene.xml\n",
      "camera_browse_1\n",
      "[camera] FAILURE - Contact ratio: 0.00\n",
      "knife_peel_1_s10_scene.xml\n",
      "knife_peel_1\n",
      "[knife] FAILURE - Contact ratio: 0.00\n",
      "toothbrush_pass_1_s3_scene.xml\n",
      "toothbrush_pass_1\n",
      "[toothbrush] FAILURE - Contact ratio: 0.00\n",
      "camera_takepicture_3_s6_scene.xml\n",
      "camera_takepicture_3\n",
      "[camera] FAILURE - Contact ratio: 0.00\n",
      "camera_takepicture_2_s2_scene.xml\n",
      "camera_takepicture_2\n",
      "[camera] FAILURE - Contact ratio: 0.00\n",
      "toothbrush_lift_s1_scene.xml\n",
      "toothbrush_lift\n",
      "-----------------------------------------\n",
      "| embeddings/             |             |\n",
      "|    dim_0_mean           | 0.22720008  |\n",
      "|    dim_0_std            | 0.33652073  |\n",
      "|    dim_1_mean           | 0.16976628  |\n",
      "|    dim_1_std            | 0.31452113  |\n",
      "|    dim_2_mean           | 0.07822708  |\n",
      "|    dim_2_std            | 0.24319409  |\n",
      "|    dim_3_mean           | 0.055843942 |\n",
      "|    dim_3_std            | 0.24363105  |\n",
      "|    max_norm             | 1.0583005   |\n",
      "|    mean_norm            | 0.67657787  |\n",
      "|    min_norm             | 0.24225417  |\n",
      "|    std_norm             | 0.28642362  |\n",
      "| eval/                   |             |\n",
      "|    mean_reward          | -9.94       |\n",
      "|    std_reward           | 1.02        |\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 128         |\n",
      "|    ep_rew_mean          | -9.7        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 12          |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 1313        |\n",
      "|    total_timesteps      | 16384       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009379389 |\n",
      "|    clip_fraction        | 0.144       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    clip_range_vf        | 0.2         |\n",
      "|    entropy_loss         | -25.9       |\n",
      "|    explained_variance   | -0.619      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 30.8        |\n",
      "|    n_updates            | 70          |\n",
      "|    policy_gradient_loss | -0.0118     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 56.3        |\n",
      "-----------------------------------------\n",
      "[toothbrush] FAILURE - Contact ratio: 0.00\n",
      "train_lift_s5_scene.xml\n",
      "train_lift\n",
      "[train] FAILURE - Contact ratio: 0.00\n",
      "cylindersmall_pass_1_s5_scene.xml\n",
      "cylindersmall_pass_1\n",
      "toothbrush_pass_1_s9_scene.xml\n",
      "toothbrush_pass_1\n",
      "[toothbrush] FAILURE - Contact ratio: 0.00\n",
      "knife_peel_1_s8_scene.xml\n",
      "knife_peel_1\n",
      "[knife] FAILURE - Contact ratio: 0.00\n",
      "knife_pass_1_s10_scene.xml\n",
      "knife_pass_1\n",
      "[knife] FAILURE - Contact ratio: 0.00\n",
      "cylindersmall_pass_1_s4_scene.xml\n",
      "cylindersmall_pass_1\n",
      "[cylindersmall] FAILURE - Contact ratio: 0.00\n",
      "toothbrush_pass_1_s8_scene.xml\n",
      "toothbrush_pass_1\n",
      "[toothbrush] FAILURE - Contact ratio: 0.00\n",
      "apple_pass_1_s5_scene.xml\n",
      "apple_pass_1\n",
      "[apple] FAILURE - Contact ratio: 0.01\n",
      "train_pass_1_s8_scene.xml\n",
      "train_pass_1\n",
      "[train] FAILURE - Contact ratio: 0.00\n",
      "camera_takepicture_3_s10_scene.xml\n",
      "camera_takepicture_3\n",
      "[camera] FAILURE - Contact ratio: 0.00\n",
      "knife_lift_s6_scene.xml\n",
      "knife_lift\n",
      "[knife] FAILURE - Contact ratio: 0.00\n",
      "knife_lift_s1_scene.xml\n",
      "knife_lift\n",
      "[knife] FAILURE - Contact ratio: 0.00\n",
      "toothbrush_brush_1_s3_scene.xml\n",
      "toothbrush_brush_1\n",
      "[toothbrush] FAILURE - Contact ratio: 0.00\n",
      "camera_offhand_1_s8_scene.xml\n",
      "camera_offhand_1\n",
      "[camera] FAILURE - Contact ratio: 0.00\n",
      "cylindersmall_pass_1_s6_scene.xml\n",
      "cylindersmall_pass_1\n",
      "train_play_1_s6_scene.xml\n",
      "train_play_1\n",
      "[train] FAILURE - Contact ratio: 0.01\n",
      "knife_peel_1_s8_scene.xml\n",
      "knife_peel_1\n",
      "[knife] FAILURE - Contact ratio: 0.00\n",
      "knife_peel_1_s10_scene.xml\n",
      "knife_peel_1\n",
      "[knife] FAILURE - Contact ratio: 0.00\n",
      "cylindersmall_lift_s8_scene.xml\n",
      "cylindersmall_lift\n",
      "[cylindersmall] FAILURE - Contact ratio: 0.00\n",
      "toothbrush_brush_1_s8_scene.xml\n",
      "toothbrush_brush_1\n",
      "[toothbrush] FAILURE - Contact ratio: 0.00\n",
      "apple_offhand_1_s1_scene.xml\n",
      "apple_offhand_1\n",
      "[apple] FAILURE - Contact ratio: 0.00\n",
      "camera_offhand_1_s1_scene.xml\n",
      "camera_offhand_1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[camera] FAILURE - Contact ratio: 0.01\n",
      "camera_pass_1_s4_scene.xml\n",
      "camera_pass_1\n",
      "[camera] FAILURE - Contact ratio: 0.00\n",
      "camera_pass_1_s6_scene.xml\n",
      "camera_pass_1\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_reward          | -9.86e+04   |\n",
      "|    std_reward           | 1.97e+05    |\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 128         |\n",
      "|    ep_rew_mean          | -9.7        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 12          |\n",
      "|    iterations           | 9           |\n",
      "|    time_elapsed         | 1464        |\n",
      "|    total_timesteps      | 18432       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012516878 |\n",
      "|    clip_fraction        | 0.0901      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    clip_range_vf        | 0.2         |\n",
      "|    entropy_loss         | -25.9       |\n",
      "|    explained_variance   | 0.0733      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 16.2        |\n",
      "|    n_updates            | 80          |\n",
      "|    policy_gradient_loss | -0.00709    |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 21.7        |\n",
      "-----------------------------------------\n",
      "[camera] FAILURE - Contact ratio: 0.00\n",
      "camera_takepicture_1_s3_scene.xml\n",
      "camera_takepicture_1\n",
      "[camera] FAILURE - Contact ratio: 0.00\n",
      "train_pass_1_s5_scene.xml\n",
      "train_pass_1\n",
      "[train] FAILURE - Contact ratio: 0.00\n",
      "knife_lift_s1_scene.xml\n",
      "knife_lift\n",
      "[knife] FAILURE - Contact ratio: 0.00\n",
      "apple_pass_1_s7_scene.xml\n",
      "apple_pass_1\n",
      "train_lift_s8_scene.xml\n",
      "train_lift\n",
      "[train] FAILURE - Contact ratio: 0.00\n",
      "train_play_1_s7_scene.xml\n",
      "train_play_1\n",
      "[train] FAILURE - Contact ratio: 0.00\n",
      "cylindersmall_inspect_1_s7_scene.xml\n",
      "cylindersmall_inspect_1\n",
      "[cylindersmall] FAILURE - Contact ratio: 0.00\n",
      "camera_offhand_1_s1_scene.xml\n",
      "camera_offhand_1\n",
      "[camera] FAILURE - Contact ratio: 0.00\n",
      "toothbrush_lift_s2_scene.xml\n",
      "toothbrush_lift\n",
      "[toothbrush] FAILURE - Contact ratio: 0.00\n",
      "cylindersmall_pass_1_s9_scene.xml\n",
      "cylindersmall_pass_1\n",
      "apple_eat_1_s7_scene.xml\n",
      "apple_eat_1\n",
      "[apple] FAILURE - Contact ratio: 0.00\n",
      "camera_pass_1_s4_scene.xml\n",
      "camera_pass_1\n",
      "[camera] FAILURE - Contact ratio: 0.00\n",
      "camera_pass_1_s10_scene.xml\n",
      "camera_pass_1\n",
      "[camera] FAILURE - Contact ratio: 0.00\n",
      "toothbrush_pass_1_s4_scene.xml\n",
      "toothbrush_pass_1\n",
      "[toothbrush] FAILURE - Contact ratio: 0.00\n",
      "cylindersmall_pass_1_s4_scene.xml\n",
      "cylindersmall_pass_1\n",
      "[cylindersmall] FAILURE - Contact ratio: 0.00\n",
      "cylindersmall_inspect_1_s7_scene.xml\n",
      "cylindersmall_inspect_1\n",
      "-----------------------------------------\n",
      "| embeddings/             |             |\n",
      "|    dim_0_mean           | 0.22720008  |\n",
      "|    dim_0_std            | 0.33652073  |\n",
      "|    dim_1_mean           | 0.16976628  |\n",
      "|    dim_1_std            | 0.31452113  |\n",
      "|    dim_2_mean           | 0.07822708  |\n",
      "|    dim_2_std            | 0.24319409  |\n",
      "|    dim_3_mean           | 0.055843942 |\n",
      "|    dim_3_std            | 0.24363105  |\n",
      "|    max_norm             | 1.0583005   |\n",
      "|    mean_norm            | 0.67657787  |\n",
      "|    min_norm             | 0.24225417  |\n",
      "|    std_norm             | 0.28642362  |\n",
      "| eval/                   |             |\n",
      "|    mean_reward          | -9.86e+04   |\n",
      "|    std_reward           | 1.97e+05    |\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 128         |\n",
      "|    ep_rew_mean          | -9.68       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 12          |\n",
      "|    iterations           | 10          |\n",
      "|    time_elapsed         | 1618        |\n",
      "|    total_timesteps      | 20480       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.00978769  |\n",
      "|    clip_fraction        | 0.0834      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    clip_range_vf        | 0.2         |\n",
      "|    entropy_loss         | -25.9       |\n",
      "|    explained_variance   | -0.0504     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 7.59        |\n",
      "|    n_updates            | 90          |\n",
      "|    policy_gradient_loss | -0.0117     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 14.4        |\n",
      "-----------------------------------------\n",
      "apple_lift_s2_scene.xml\n",
      "apple_lift\n",
      "[apple] FAILURE - Contact ratio: 0.00\n",
      "camera_pass_1_s2_scene.xml\n",
      "camera_pass_1\n",
      "[camera] FAILURE - Contact ratio: 0.00\n",
      "apple_eat_1_s8_scene.xml\n",
      "apple_eat_1\n",
      "[apple] FAILURE - Contact ratio: 0.00\n",
      "toothbrush_brush_1_s8_scene.xml\n",
      "toothbrush_brush_1\n",
      "[toothbrush] FAILURE - Contact ratio: 0.00\n",
      "apple_pass_1_s10_scene.xml\n",
      "apple_pass_1\n",
      "[apple] FAILURE - Contact ratio: 0.00\n",
      "knife_chop_1_s8_scene.xml\n",
      "knife_chop_1\n",
      "[knife] FAILURE - Contact ratio: 0.00\n",
      "knife_lift_s1_scene.xml\n",
      "knife_lift\n",
      "[knife] FAILURE - Contact ratio: 0.00\n",
      "camera_takepicture_1_s9_scene.xml\n",
      "camera_takepicture_1\n",
      "[camera] FAILURE - Contact ratio: 0.00\n",
      "knife_peel_1_s6_scene.xml\n",
      "knife_peel_1\n",
      "[knife] FAILURE - Contact ratio: 0.00\n",
      "apple_offhand_1_s1_scene.xml\n",
      "apple_offhand_1\n",
      "[apple] FAILURE - Contact ratio: 0.00\n",
      "toothbrush_brush_1_s5_scene.xml\n",
      "toothbrush_brush_1\n",
      "[toothbrush] FAILURE - Contact ratio: 0.00\n",
      "train_lift_s3_scene.xml\n",
      "train_lift\n",
      "[train] FAILURE - Contact ratio: 0.02\n",
      "elephant_pass_1_s3_scene.xml\n",
      "elephant_pass_1\n",
      "cylindersmall_inspect_1_s10_scene.xml\n",
      "cylindersmall_inspect_1\n",
      "[cylindersmall] FAILURE - Contact ratio: 0.00\n",
      "cylindersmall_pass_1_s7_scene.xml\n",
      "cylindersmall_pass_1\n",
      "[cylindersmall] FAILURE - Contact ratio: 0.00\n",
      "knife_peel_1_s6_scene.xml\n",
      "knife_peel_1\n",
      "[knife] FAILURE - Contact ratio: 0.00\n",
      "camera_browse_1_s10_scene.xml\n",
      "camera_browse_1\n",
      "[camera] FAILURE - Contact ratio: 0.00\n",
      "elephant_inspect_1_s6_scene.xml\n",
      "elephant_inspect_1\n",
      "[elephant] FAILURE - Contact ratio: 0.00\n",
      "elephant_inspect_1_s6_scene.xml\n",
      "elephant_inspect_1\n",
      "[elephant] FAILURE - Contact ratio: 0.00\n",
      "toothbrush_lift_s2_scene.xml\n",
      "toothbrush_lift\n",
      "[toothbrush] FAILURE - Contact ratio: 0.00\n",
      "cylindersmall_lift_s1_scene.xml\n",
      "cylindersmall_lift\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_reward          | -1.97e+05   |\n",
      "|    std_reward           | 2.41e+05    |\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 128         |\n",
      "|    ep_rew_mean          | -9.62       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 12          |\n",
      "|    iterations           | 11          |\n",
      "|    time_elapsed         | 1767        |\n",
      "|    total_timesteps      | 22528       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008369276 |\n",
      "|    clip_fraction        | 0.0775      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    clip_range_vf        | 0.2         |\n",
      "|    entropy_loss         | -26         |\n",
      "|    explained_variance   | 0.124       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 6.38        |\n",
      "|    n_updates            | 100         |\n",
      "|    policy_gradient_loss | -0.0052     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 35.4        |\n",
      "-----------------------------------------\n",
      "toothbrush_pass_1_s4_scene.xml\n",
      "toothbrush_pass_1\n",
      "[toothbrush] FAILURE - Contact ratio: 0.00\n",
      "apple_lift_s4_scene.xml\n",
      "apple_lift\n",
      "[apple] FAILURE - Contact ratio: 0.00\n",
      "toothbrush_brush_1_s5_scene.xml\n",
      "toothbrush_brush_1\n",
      "[toothbrush] FAILURE - Contact ratio: 0.00\n",
      "knife_pass_1_s10_scene.xml\n",
      "knife_pass_1\n",
      "[knife] FAILURE - Contact ratio: 0.00\n",
      "apple_pass_1_s9_scene.xml\n",
      "apple_pass_1\n",
      "[apple] FAILURE - Contact ratio: 0.00\n",
      "apple_lift_s1_scene.xml\n",
      "apple_lift\n",
      "[apple] FAILURE - Contact ratio: 0.00\n",
      "cylindersmall_inspect_1_s7_scene.xml\n",
      "cylindersmall_inspect_1\n",
      "cylindersmall_inspect_1_s6_scene.xml\n",
      "cylindersmall_inspect_1\n",
      "[cylindersmall] FAILURE - Contact ratio: 0.00\n",
      "cylindersmall_inspect_1_s1_scene.xml\n",
      "cylindersmall_inspect_1\n",
      "[cylindersmall] FAILURE - Contact ratio: 0.00\n",
      "apple_lift_s7_scene.xml\n",
      "apple_lift\n",
      "[apple] FAILURE - Contact ratio: 0.00\n",
      "cylindersmall_pass_1_s7_scene.xml\n",
      "cylindersmall_pass_1\n",
      "[cylindersmall] FAILURE - Contact ratio: 0.00\n",
      "apple_lift_s2_scene.xml\n",
      "apple_lift\n",
      "[apple] FAILURE - Contact ratio: 0.00\n",
      "knife_pass_1_s8_scene.xml\n",
      "knife_pass_1\n",
      "[knife] FAILURE - Contact ratio: 0.00\n",
      "toothbrush_pass_1_s7_scene.xml\n",
      "toothbrush_pass_1\n",
      "[toothbrush] FAILURE - Contact ratio: 0.00\n",
      "apple_eat_1_s1_scene.xml\n",
      "apple_eat_1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[apple] FAILURE - Contact ratio: 0.00\n",
      "elephant_pass_1_s2_scene.xml\n",
      "elephant_pass_1\n",
      "[elephant] FAILURE - Contact ratio: 0.04\n",
      "cylindersmall_inspect_1_s3_scene.xml\n",
      "cylindersmall_inspect_1\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_reward          | -2.95e+05   |\n",
      "|    std_reward           | 2.41e+05    |\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 128         |\n",
      "|    ep_rew_mean          | -9.63       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 12          |\n",
      "|    iterations           | 12          |\n",
      "|    time_elapsed         | 1980        |\n",
      "|    total_timesteps      | 24576       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006440622 |\n",
      "|    clip_fraction        | 0.0979      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    clip_range_vf        | 0.2         |\n",
      "|    entropy_loss         | -26.1       |\n",
      "|    explained_variance   | 0.177       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 18.6        |\n",
      "|    n_updates            | 110         |\n",
      "|    policy_gradient_loss | -0.00824    |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 42.6        |\n",
      "-----------------------------------------\n",
      "camera_takepicture_3_s4_scene.xml\n",
      "camera_takepicture_3\n",
      "[camera] FAILURE - Contact ratio: 0.00\n",
      "cylindersmall_inspect_1_s8_scene.xml\n",
      "cylindersmall_inspect_1\n",
      "[cylindersmall] FAILURE - Contact ratio: 0.00\n",
      "train_pass_1_s3_scene.xml\n",
      "train_pass_1\n",
      "[train] FAILURE - Contact ratio: 0.00\n",
      "knife_peel_1_s8_scene.xml\n",
      "knife_peel_1\n",
      "[knife] FAILURE - Contact ratio: 0.00\n",
      "camera_takepicture_1_s9_scene.xml\n",
      "camera_takepicture_1\n",
      "[camera] FAILURE - Contact ratio: 0.00\n",
      "knife_chop_1_s10_scene.xml\n",
      "knife_chop_1\n",
      "[knife] FAILURE - Contact ratio: 0.00\n",
      "cylindersmall_inspect_1_s8_scene.xml\n",
      "cylindersmall_inspect_1\n",
      "camera_takepicture_3_s3_scene.xml\n",
      "camera_takepicture_3\n",
      "[camera] FAILURE - Contact ratio: 0.00\n",
      "train_pass_1_s8_scene.xml\n",
      "train_pass_1\n",
      "[train] FAILURE - Contact ratio: 0.00\n",
      "knife_pass_1_s10_scene.xml\n",
      "knife_pass_1\n",
      "[knife] FAILURE - Contact ratio: 0.00\n",
      "train_pass_1_s6_scene.xml\n",
      "train_pass_1\n",
      "[train] FAILURE - Contact ratio: 0.00\n",
      "toothbrush_pass_1_s8_scene.xml\n",
      "toothbrush_pass_1\n",
      "[toothbrush] FAILURE - Contact ratio: 0.00\n",
      "cylindersmall_pass_1_s3_scene.xml\n",
      "cylindersmall_pass_1\n",
      "-----------------------------------------\n",
      "| embeddings/             |             |\n",
      "|    dim_0_mean           | 0.22720008  |\n",
      "|    dim_0_std            | 0.33652073  |\n",
      "|    dim_1_mean           | 0.16976628  |\n",
      "|    dim_1_std            | 0.31452113  |\n",
      "|    dim_2_mean           | 0.07822708  |\n",
      "|    dim_2_std            | 0.24319409  |\n",
      "|    dim_3_mean           | 0.055843942 |\n",
      "|    dim_3_std            | 0.24363105  |\n",
      "|    max_norm             | 1.0583005   |\n",
      "|    mean_norm            | 0.67657787  |\n",
      "|    min_norm             | 0.24225417  |\n",
      "|    std_norm             | 0.28642362  |\n",
      "| eval/                   |             |\n",
      "|    mean_reward          | -9.57       |\n",
      "|    std_reward           | 0.336       |\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 128         |\n",
      "|    ep_rew_mean          | -9.62       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 13          |\n",
      "|    iterations           | 13          |\n",
      "|    time_elapsed         | 2043        |\n",
      "|    total_timesteps      | 26624       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008810966 |\n",
      "|    clip_fraction        | 0.0832      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    clip_range_vf        | 0.2         |\n",
      "|    entropy_loss         | -26.1       |\n",
      "|    explained_variance   | 0.16        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 35.9        |\n",
      "|    n_updates            | 120         |\n",
      "|    policy_gradient_loss | -0.00684    |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 33.5        |\n",
      "-----------------------------------------\n",
      "toothbrush_pass_1_s7_scene.xml\n",
      "toothbrush_pass_1\n",
      "[toothbrush] FAILURE - Contact ratio: 0.00\n",
      "toothbrush_pass_1_s7_scene.xml\n",
      "toothbrush_pass_1\n",
      "[toothbrush] FAILURE - Contact ratio: 0.00\n",
      "cylindersmall_pass_1_s6_scene.xml\n",
      "cylindersmall_pass_1\n",
      "[cylindersmall] FAILURE - Contact ratio: 0.00\n",
      "knife_peel_1_s6_scene.xml\n",
      "knife_peel_1\n",
      "[knife] FAILURE - Contact ratio: 0.00\n",
      "apple_pass_1_s10_scene.xml\n",
      "apple_pass_1\n",
      "[apple] FAILURE - Contact ratio: 0.00\n",
      "camera_lift_s6_scene.xml\n",
      "camera_lift\n",
      "[camera] FAILURE - Contact ratio: 0.00\n",
      "cylindersmall_inspect_1_s1_scene.xml\n",
      "cylindersmall_inspect_1\n",
      "apple_lift_s9_scene.xml\n",
      "apple_lift\n",
      "[apple] FAILURE - Contact ratio: 0.00\n",
      "camera_takepicture_2_s8_scene.xml\n",
      "camera_takepicture_2\n",
      "[camera] FAILURE - Contact ratio: 0.00\n",
      "cylindersmall_pass_1_s9_scene.xml\n",
      "cylindersmall_pass_1\n",
      "[cylindersmall] FAILURE - Contact ratio: 0.00\n",
      "train_play_1_s1_scene.xml\n",
      "train_play_1\n",
      "[train] FAILURE - Contact ratio: 0.00\n",
      "cylindersmall_lift_s4_scene.xml\n",
      "cylindersmall_lift\n",
      "[cylindersmall] FAILURE - Contact ratio: 0.00\n",
      "camera_pass_1_s8_scene.xml\n",
      "camera_pass_1\n",
      "[camera] FAILURE - Contact ratio: 0.00\n",
      "apple_pass_1_s2_scene.xml\n",
      "apple_pass_1\n",
      "[apple] FAILURE - Contact ratio: 0.00\n",
      "toothbrush_pass_1_s9_scene.xml\n",
      "toothbrush_pass_1\n",
      "[toothbrush] FAILURE - Contact ratio: 0.00\n",
      "cylindersmall_inspect_1_s8_scene.xml\n",
      "cylindersmall_inspect_1\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_reward          | -1.97e+05   |\n",
      "|    std_reward           | 2.41e+05    |\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 128         |\n",
      "|    ep_rew_mean          | -9.61       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 12          |\n",
      "|    iterations           | 14          |\n",
      "|    time_elapsed         | 2210        |\n",
      "|    total_timesteps      | 28672       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004926068 |\n",
      "|    clip_fraction        | 0.0492      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    clip_range_vf        | 0.2         |\n",
      "|    entropy_loss         | -26.1       |\n",
      "|    explained_variance   | 0.129       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 28.1        |\n",
      "|    n_updates            | 130         |\n",
      "|    policy_gradient_loss | -0.00367    |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 32.1        |\n",
      "-----------------------------------------\n",
      "apple_pass_1_s5_scene.xml\n",
      "apple_pass_1\n",
      "[apple] FAILURE - Contact ratio: 0.00\n",
      "cylindersmall_inspect_1_s3_scene.xml\n",
      "cylindersmall_inspect_1\n",
      "[cylindersmall] FAILURE - Contact ratio: 0.00\n",
      "cylindersmall_offhand_1_s1_scene.xml\n",
      "cylindersmall_offhand_1\n",
      "[cylindersmall] FAILURE - Contact ratio: 0.00\n",
      "cylindersmall_lift_s1_scene.xml\n",
      "cylindersmall_lift\n",
      "[cylindersmall] FAILURE - Contact ratio: 0.00\n",
      "toothbrush_pass_1_s3_scene.xml\n",
      "toothbrush_pass_1\n",
      "[toothbrush] FAILURE - Contact ratio: 0.00\n",
      "apple_eat_1_s10_scene.xml\n",
      "apple_eat_1\n",
      "[apple] FAILURE - Contact ratio: 0.00\n",
      "train_play_1_s10_scene.xml\n",
      "train_play_1\n",
      "[train] FAILURE - Contact ratio: 0.00\n",
      "cylindersmall_pass_1_s10_scene.xml\n",
      "cylindersmall_pass_1\n",
      "apple_lift_s9_scene.xml\n",
      "apple_lift\n",
      "[apple] FAILURE - Contact ratio: 0.00\n",
      "toothbrush_pass_1_s3_scene.xml\n",
      "toothbrush_pass_1\n",
      "[toothbrush] FAILURE - Contact ratio: 0.00\n",
      "camera_takepicture_2_s2_scene.xml\n",
      "camera_takepicture_2\n",
      "[camera] FAILURE - Contact ratio: 0.00\n",
      "cylindersmall_pass_1_s2_scene.xml\n",
      "cylindersmall_pass_1\n",
      "[cylindersmall] FAILURE - Contact ratio: 0.00\n",
      "train_lift_s10_scene.xml\n",
      "train_lift\n",
      "[train] FAILURE - Contact ratio: 0.00\n",
      "train_play_1_s3_scene.xml\n",
      "train_play_1\n",
      "[train] FAILURE - Contact ratio: 0.00\n",
      "camera_pass_1_s9_scene.xml\n",
      "camera_pass_1\n",
      "[camera] FAILURE - Contact ratio: 0.00\n",
      "cylindersmall_lift_s1_scene.xml\n",
      "cylindersmall_lift\n",
      "------------------------------------------\n",
      "| embeddings/             |              |\n",
      "|    dim_0_mean           | 0.22720008   |\n",
      "|    dim_0_std            | 0.33652073   |\n",
      "|    dim_1_mean           | 0.16976628   |\n",
      "|    dim_1_std            | 0.31452113   |\n",
      "|    dim_2_mean           | 0.07822708   |\n",
      "|    dim_2_std            | 0.24319409   |\n",
      "|    dim_3_mean           | 0.055843942  |\n",
      "|    dim_3_std            | 0.24363105   |\n",
      "|    max_norm             | 1.0583005    |\n",
      "|    mean_norm            | 0.67657787   |\n",
      "|    min_norm             | 0.24225417   |\n",
      "|    std_norm             | 0.28642362   |\n",
      "| eval/                   |              |\n",
      "|    mean_reward          | -9.86e+04    |\n",
      "|    std_reward           | 1.97e+05     |\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 128          |\n",
      "|    ep_rew_mean          | -9.58        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 12           |\n",
      "|    iterations           | 15           |\n",
      "|    time_elapsed         | 2416         |\n",
      "|    total_timesteps      | 30720        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0077403253 |\n",
      "|    clip_fraction        | 0.0671       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    clip_range_vf        | 0.2          |\n",
      "|    entropy_loss         | -26.1        |\n",
      "|    explained_variance   | 0.357        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 28           |\n",
      "|    n_updates            | 140          |\n",
      "|    policy_gradient_loss | -0.00476     |\n",
      "|    std                  | 1.04         |\n",
      "|    value_loss           | 40.4         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "knife_lift_s6_scene.xml\n",
      "knife_lift\n",
      "[knife] FAILURE - Contact ratio: 0.00\n",
      "knife_pass_1_s9_scene.xml\n",
      "knife_pass_1\n",
      "[knife] FAILURE - Contact ratio: 0.00\n",
      "train_lift_s4_scene.xml\n",
      "train_lift\n",
      "[train] FAILURE - Contact ratio: 0.04\n",
      "cylindersmall_inspect_1_s7_scene.xml\n",
      "cylindersmall_inspect_1\n",
      "[cylindersmall] FAILURE - Contact ratio: 0.00\n",
      "toothbrush_pass_1_s4_scene.xml\n",
      "toothbrush_pass_1\n",
      "[toothbrush] FAILURE - Contact ratio: 0.00\n",
      "knife_lift_s6_scene.xml\n",
      "knife_lift\n",
      "[knife] FAILURE - Contact ratio: 0.00\n",
      "toothbrush_brush_1_s3_scene.xml\n",
      "toothbrush_brush_1\n",
      "[toothbrush] FAILURE - Contact ratio: 0.00\n",
      "apple_lift_s8_scene.xml\n",
      "apple_lift\n",
      "[apple] FAILURE - Contact ratio: 0.00\n",
      "knife_lift_s3_scene.xml\n",
      "knife_lift\n",
      "[knife] FAILURE - Contact ratio: 0.00\n",
      "apple_lift_s1_scene.xml\n",
      "apple_lift\n",
      "[apple] FAILURE - Contact ratio: 0.00\n",
      "camera_offhand_1_s3_scene.xml\n",
      "camera_offhand_1\n",
      "[camera] FAILURE - Contact ratio: 0.00\n",
      "cup_pass_1_s6_scene.xml\n",
      "cup_pass_1\n",
      "[cup] FAILURE - Contact ratio: 0.00\n",
      "knife_lift_s6_scene.xml\n",
      "knife_lift\n",
      "cup_lift_s6_scene.xml\n",
      "cup_lift\n",
      "[cup] FAILURE - Contact ratio: 0.00\n",
      "camera_takepicture_1_s9_scene.xml\n",
      "camera_takepicture_1\n",
      "[camera] FAILURE - Contact ratio: 0.00\n",
      "cylindersmall_inspect_1_s9_scene.xml\n",
      "cylindersmall_inspect_1\n",
      "[cylindersmall] FAILURE - Contact ratio: 0.00\n",
      "camera_browse_1_s8_scene.xml\n",
      "camera_browse_1\n",
      "[camera] FAILURE - Contact ratio: 0.00\n",
      "camera_takepicture_3_s6_scene.xml\n",
      "camera_takepicture_3\n",
      "[camera] FAILURE - Contact ratio: 0.00\n",
      "camera_offhand_1_s3_scene.xml\n",
      "camera_offhand_1\n",
      "[camera] FAILURE - Contact ratio: 0.00\n",
      "cup_drink_1_s1_scene.xml\n",
      "cup_drink_1\n",
      "[cup] FAILURE - Contact ratio: 0.00\n",
      "cylindersmall_pass_1_s1_scene.xml\n",
      "cylindersmall_pass_1\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_reward          | -9.85e+04   |\n",
      "|    std_reward           | 1.97e+05    |\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 128         |\n",
      "|    ep_rew_mean          | -9.6        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 12          |\n",
      "|    iterations           | 16          |\n",
      "|    time_elapsed         | 2531        |\n",
      "|    total_timesteps      | 32768       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006307369 |\n",
      "|    clip_fraction        | 0.0682      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    clip_range_vf        | 0.2         |\n",
      "|    entropy_loss         | -26.2       |\n",
      "|    explained_variance   | 0.671       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 24          |\n",
      "|    n_updates            | 150         |\n",
      "|    policy_gradient_loss | -0.00875    |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 19.2        |\n",
      "-----------------------------------------\n",
      "cylindersmall_offhand_1_s1_scene.xml\n",
      "cylindersmall_offhand_1\n",
      "[cylindersmall] FAILURE - Contact ratio: 0.00\n",
      "cup_drink_1_s4_scene.xml\n",
      "cup_drink_1\n",
      "[cup] FAILURE - Contact ratio: 0.00\n",
      "camera_takepicture_3_s6_scene.xml\n",
      "camera_takepicture_3\n",
      "[camera] FAILURE - Contact ratio: 0.00\n",
      "camera_pass_1_s2_scene.xml\n",
      "camera_pass_1\n",
      "[camera] FAILURE - Contact ratio: 0.00\n",
      "apple_eat_1_s7_scene.xml\n",
      "apple_eat_1\n",
      "[apple] FAILURE - Contact ratio: 0.00\n",
      "apple_pass_1_s8_scene.xml\n",
      "apple_pass_1\n",
      "[apple] FAILURE - Contact ratio: 0.00\n",
      "cup_pour_1_s1_scene.xml\n",
      "cup_pour_1\n",
      "[cup] FAILURE - Contact ratio: 0.00\n",
      "camera_browse_1_s7_scene.xml\n",
      "camera_browse_1\n",
      "[camera] FAILURE - Contact ratio: 0.00\n",
      "cup_lift_s1_scene.xml\n",
      "cup_lift\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "XML Error: Error opening file '/home/diego/TFM/models/objects/cup_lift_object_s1.xml': No such file or directory\nElement 'include', line 3\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 1086\u001b[0m\n\u001b[1;32m   1082\u001b[0m phase_timesteps \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m(phase[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimesteps\u001b[39m\u001b[38;5;124m\"\u001b[39m], total_timesteps \u001b[38;5;241m-\u001b[39m total_trained)\n\u001b[1;32m   1084\u001b[0m send_text(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStarting phase \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcurrent_phase\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m with \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mphase_timesteps\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m timesteps\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 1086\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlearn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1087\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtotal_timesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mphase_timesteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1088\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimproved_callback\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membedding_callback\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1089\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreset_num_timesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[1;32m   1090\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1092\u001b[0m total_trained \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m phase_timesteps\n\u001b[1;32m   1094\u001b[0m \u001b[38;5;66;03m# Evaluate and save\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/sb3_contrib/ppo_recurrent/ppo_recurrent.py:450\u001b[0m, in \u001b[0;36mRecurrentPPO.learn\u001b[0;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[0m\n\u001b[1;32m    441\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mlearn\u001b[39m(\n\u001b[1;32m    442\u001b[0m     \u001b[38;5;28mself\u001b[39m: SelfRecurrentPPO,\n\u001b[1;32m    443\u001b[0m     total_timesteps: \u001b[38;5;28mint\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    448\u001b[0m     progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    449\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m SelfRecurrentPPO:\n\u001b[0;32m--> 450\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlearn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    451\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtotal_timesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtotal_timesteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    452\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    453\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlog_interval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlog_interval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    454\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtb_log_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtb_log_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    455\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreset_num_timesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreset_num_timesteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    456\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    457\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/stable_baselines3/common/on_policy_algorithm.py:324\u001b[0m, in \u001b[0;36mOnPolicyAlgorithm.learn\u001b[0;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[0m\n\u001b[1;32m    321\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menv \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    323\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_timesteps \u001b[38;5;241m<\u001b[39m total_timesteps:\n\u001b[0;32m--> 324\u001b[0m     continue_training \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollect_rollouts\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrollout_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_rollout_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_steps\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    326\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m continue_training:\n\u001b[1;32m    327\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/sb3_contrib/ppo_recurrent/ppo_recurrent.py:252\u001b[0m, in \u001b[0;36mRecurrentPPO.collect_rollouts\u001b[0;34m(self, env, callback, rollout_buffer, n_rollout_steps)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maction_space, spaces\u001b[38;5;241m.\u001b[39mBox):\n\u001b[1;32m    250\u001b[0m     clipped_actions \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mclip(actions, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maction_space\u001b[38;5;241m.\u001b[39mlow, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maction_space\u001b[38;5;241m.\u001b[39mhigh)\n\u001b[0;32m--> 252\u001b[0m new_obs, rewards, dones, infos \u001b[38;5;241m=\u001b[39m \u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclipped_actions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_timesteps \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m env\u001b[38;5;241m.\u001b[39mnum_envs\n\u001b[1;32m    256\u001b[0m \u001b[38;5;66;03m# Give access to local variables\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/stable_baselines3/common/vec_env/base_vec_env.py:222\u001b[0m, in \u001b[0;36mVecEnv.step\u001b[0;34m(self, actions)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    216\u001b[0m \u001b[38;5;124;03mStep the environments with the given action\u001b[39;00m\n\u001b[1;32m    217\u001b[0m \n\u001b[1;32m    218\u001b[0m \u001b[38;5;124;03m:param actions: the action\u001b[39;00m\n\u001b[1;32m    219\u001b[0m \u001b[38;5;124;03m:return: observation, reward, done, information\u001b[39;00m\n\u001b[1;32m    220\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    221\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstep_async(actions)\n\u001b[0;32m--> 222\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep_wait\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/stable_baselines3/common/vec_env/dummy_vec_env.py:71\u001b[0m, in \u001b[0;36mDummyVecEnv.step_wait\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuf_dones[env_idx]:\n\u001b[1;32m     69\u001b[0m         \u001b[38;5;66;03m# save final observation where user can get it, then reset\u001b[39;00m\n\u001b[1;32m     70\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuf_infos[env_idx][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mterminal_observation\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m obs\n\u001b[0;32m---> 71\u001b[0m         obs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreset_infos[env_idx] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menvs\u001b[49m\u001b[43m[\u001b[49m\u001b[43menv_idx\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreset\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_save_obs(env_idx, obs)\n\u001b[1;32m     73\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_obs_from_buf(), np\u001b[38;5;241m.\u001b[39mcopy(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuf_rews), np\u001b[38;5;241m.\u001b[39mcopy(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuf_dones), deepcopy(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuf_infos))\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:83\u001b[0m, in \u001b[0;36mMonitor.reset\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m     81\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected you to pass keyword argument \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m into reset\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     82\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcurrent_reset_info[key] \u001b[38;5;241m=\u001b[39m value\n\u001b[0;32m---> 83\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreset\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[19], line 615\u001b[0m, in \u001b[0;36mMujocoEnvCNN.reset\u001b[0;34m(self, seed)\u001b[0m\n\u001b[1;32m    613\u001b[0m objeto_stl \u001b[38;5;241m=\u001b[39m check_object[objeto\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m)]\n\u001b[1;32m    614\u001b[0m model_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/home/diego/TFM/models/scenes/\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m gesture \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m sub \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_scene.xml\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 615\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m \u001b[43mmujoco\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mMjModel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_xml_path\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    616\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;241m=\u001b[39m mujoco\u001b[38;5;241m.\u001b[39mMjData(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel)\n\u001b[1;32m    618\u001b[0m \u001b[38;5;66;03m# Reinitialize body IDs for new scene\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: XML Error: Error opening file '/home/diego/TFM/models/objects/cup_lift_object_s1.xml': No such file or directory\nElement 'include', line 3\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import torch\n",
    "import mujoco\n",
    "import mujoco.viewer\n",
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "from scipy.spatial.transform import Rotation as R, Slerp\n",
    "import yaml\n",
    "import random\n",
    "import re\n",
    "import mlflow\n",
    "import gymnasium as gym\n",
    "from gymnasium import spaces\n",
    "import torch.nn as nn\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "from stable_baselines3.common.env_checker import check_env\n",
    "from stable_baselines3.common.callbacks import BaseCallback\n",
    "from sb3_contrib import RecurrentPPO\n",
    "import json\n",
    "from collections import deque\n",
    "\n",
    "# Configuración de Telegram (opcional)\n",
    "TELEGRAM_TOKEN = '7979041854:AAE1zqPs6nNvR-CewP2rRx0_T_enAcmjFEE'\n",
    "TELEGRAM_CHAT_ID = '1446668173'\n",
    "\n",
    "def send_text(message, token=TELEGRAM_TOKEN, chat_id=TELEGRAM_CHAT_ID):\n",
    "    \"\"\"Función para enviar mensajes por Telegram\"\"\"\n",
    "    try:\n",
    "        import requests\n",
    "        url = f\"https://api.telegram.org/bot{token}/sendMessage\"\n",
    "        data = {\"chat_id\": chat_id, \"text\": message}\n",
    "        requests.post(url, data=data)\n",
    "    except:\n",
    "        print(f\"Telegram message: {message}\")\n",
    "\n",
    "def send_video(video_path, caption=\"\", token=TELEGRAM_TOKEN, chat_id=TELEGRAM_CHAT_ID):\n",
    "    \"\"\"Función para enviar videos por Telegram\"\"\"\n",
    "    try:\n",
    "        import requests\n",
    "        url = f\"https://api.telegram.org/bot{token}/sendVideo\"\n",
    "        with open(video_path, 'rb') as video:\n",
    "            files = {'video': video}\n",
    "            data = {'chat_id': chat_id, 'caption': caption}\n",
    "            requests.post(url, files=files, data=data)\n",
    "    except Exception as e:\n",
    "        print(f\"Could not send video: {e}\")\n",
    "\n",
    "def record_final_video(model, env, video_path=\"final_agent.mp4\", max_steps=200, fps=20, log_mlflow=True):\n",
    "    \"\"\"Record a video of the trained agent using the panoramic view\"\"\"\n",
    "    obs, info = env.reset()\n",
    "    imgs = env.render()\n",
    "    \n",
    "    if isinstance(imgs, tuple) and len(imgs) >= 2:\n",
    "        frame = imgs[1]  # panoramic_view_bgr\n",
    "    else:\n",
    "        frame = imgs\n",
    "\n",
    "    height, width, _ = frame.shape\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    out = cv2.VideoWriter(video_path, fourcc, fps, (width, height))\n",
    "\n",
    "    for step in range(max_steps):\n",
    "        action, _ = model.predict(obs, deterministic=True)\n",
    "        obs, reward, done, truncated, info = env.step(action)\n",
    "\n",
    "        imgs = env.render()\n",
    "        if isinstance(imgs, tuple) and len(imgs) >= 2:\n",
    "            frame = imgs[1]\n",
    "        else:\n",
    "            frame = imgs\n",
    "            \n",
    "        out.write(frame)\n",
    "        if done:\n",
    "            print(f\"[{env.objeto}] Episode finished at step {step}, reward: {reward}\")\n",
    "            break\n",
    "\n",
    "    out.release()\n",
    "    print(f\"[{env.objeto}] Video saved to {video_path}\")\n",
    "\n",
    "    if log_mlflow:\n",
    "        try:\n",
    "            mlflow.log_artifact(video_path)\n",
    "            print(f\"[{env.objeto}] Video logged to MLflow: {video_path}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Could not log video to MLflow: {e}\")\n",
    "\n",
    "def get_camera_image(model, data, cam_name, width=400, height=400, options=None):\n",
    "    \"\"\"Get camera image from Mujoco\"\"\"\n",
    "    renderer = mujoco.Renderer(model, height=height, width=width)\n",
    "    if options is None:\n",
    "        renderer.update_scene(data, camera=cam_name)\n",
    "    else:\n",
    "        renderer.update_scene(data, cam_name, options)\n",
    "    rgb_array = renderer.render()\n",
    "    return rgb_array\n",
    "\n",
    "def extract_s_pattern(input_string):\n",
    "    \"\"\"Extract scene pattern from filename\"\"\"\n",
    "    pattern = r's\\d+'\n",
    "    match = re.search(pattern, input_string)\n",
    "    if match:\n",
    "        s_pattern = match.group()\n",
    "        before = input_string[:match.start()]\n",
    "        after = input_string[match.end():]\n",
    "        return before[:-1], s_pattern, after\n",
    "    else:\n",
    "        return None, None, None\n",
    "\n",
    "class TrainableObjectEmbeddingManager(nn.Module):\n",
    "    \"\"\"Object embeddings that can be trained during RL\"\"\"\n",
    "    \n",
    "    def __init__(self, embedding_dim=16):\n",
    "        super().__init__()\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.known_objects = self._discover_all_objects()\n",
    "        \n",
    "        # Create trainable embedding layer\n",
    "        self.embedding_layer = nn.Embedding(\n",
    "            num_embeddings=len(self.known_objects) + 1,  # +1 for unknown objects\n",
    "            embedding_dim=embedding_dim,\n",
    "            padding_idx=0  # Use index 0 for unknown objects\n",
    "        )\n",
    "        \n",
    "        # Initialize with reasonable values\n",
    "        self._initialize_embeddings()\n",
    "        \n",
    "        # Mapping from object names to indices\n",
    "        self.object_to_idx = {obj: idx+1 for idx, obj in enumerate(self.known_objects)}\n",
    "        self.object_to_idx['unknown'] = 0  # Default for unknown objects\n",
    "        \n",
    "        print(f\"Initialized trainable embeddings for {len(self.known_objects)} objects\")\n",
    "        print(f\"Objects: {self.known_objects}\")\n",
    "        \n",
    "    def _discover_all_objects(self):\n",
    "        \"\"\"Discover all object names from scene files\"\"\"\n",
    "        scenes_dir = \"/home/diego/TFM/models/scenes/\"\n",
    "        all_scenes = os.listdir(scenes_dir)\n",
    "        object_names = set()\n",
    "        \n",
    "        for scene_file in all_scenes:\n",
    "            if scene_file.endswith('_scene.xml'):\n",
    "                parts = scene_file.split('_')\n",
    "                if len(parts) >= 2:\n",
    "                    object_names.add(parts[0])\n",
    "        \n",
    "        return sorted(object_names)\n",
    "    \n",
    "    def _initialize_embeddings(self):\n",
    "        \"\"\"Initialize embeddings with geometric priors\"\"\"\n",
    "        with torch.no_grad():\n",
    "            # Initialize all embeddings with small random values first\n",
    "            nn.init.normal_(self.embedding_layer.weight, mean=0.0, std=0.1)\n",
    "            \n",
    "            # Geometric priors based on object names\n",
    "            for idx, obj_name in enumerate(self.known_objects):\n",
    "                obj_lower = obj_name.lower()\n",
    "                \n",
    "                if 'cube' in obj_lower:\n",
    "                    # Cubes: symmetric, flat surfaces\n",
    "                    init_embedding = torch.tensor([1.0, 0.0, 0.0, 0.0] + [0.1] * (self.embedding_dim - 4))\n",
    "                elif 'sphere' in obj_lower:\n",
    "                    # Spheres: perfectly symmetric\n",
    "                    init_embedding = torch.tensor([0.0, 1.0, 0.0, 0.0] + [0.1] * (self.embedding_dim - 4))\n",
    "                elif 'cylinder' in obj_lower:\n",
    "                    # Cylinders: axial symmetry\n",
    "                    init_embedding = torch.tensor([0.0, 0.0, 1.0, 0.0] + [0.1] * (self.embedding_dim - 4))\n",
    "                elif 'pyramid' in obj_lower:\n",
    "                    # Pyramids: pointed\n",
    "                    init_embedding = torch.tensor([0.0, 0.0, 0.0, 1.0] + [0.1] * (self.embedding_dim - 4))\n",
    "                elif 'torus' in obj_lower:\n",
    "                    # Torus: donut shape\n",
    "                    init_embedding = torch.tensor([0.5, 0.5, 0.0, 0.0] + [0.1] * (self.embedding_dim - 4))\n",
    "                elif any(x in obj_lower for x in ['apple', 'banana']):\n",
    "                    # Fruits: organic shapes\n",
    "                    init_embedding = torch.tensor([0.2, 0.7, 0.1, 0.0] + [0.1] * (self.embedding_dim - 4))\n",
    "                elif any(x in obj_lower for x in ['bowl', 'cup', 'mug', 'wineglass']):\n",
    "                    # Kitchen items: curved containers\n",
    "                    init_embedding = torch.tensor([0.3, 0.6, 0.1, 0.0] + [0.1] * (self.embedding_dim - 4))\n",
    "                elif any(x in obj_lower for x in ['camera', 'phone', 'flashlight']):\n",
    "                    # Electronics: rectangular with details\n",
    "                    init_embedding = torch.tensor([0.8, 0.1, 0.1, 0.0] + [0.1] * (self.embedding_dim - 4))\n",
    "                elif any(x in obj_lower for x in ['hammer', 'scissors', 'knife']):\n",
    "                    # Tools: elongated\n",
    "                    init_embedding = torch.tensor([0.7, 0.2, 0.1, 0.0] + [0.1] * (self.embedding_dim - 4))\n",
    "                else:\n",
    "                    # Default: mixed properties (keep the random initialization)\n",
    "                    continue\n",
    "                \n",
    "                # Apply the geometric prior\n",
    "                self.embedding_layer.weight.data[idx+1] = init_embedding\n",
    "    \n",
    "    def get_embedding(self, object_name, as_tensor=False):\n",
    "        \"\"\"Get embedding for object - returns tensor for training\"\"\"\n",
    "        obj_idx = self.object_to_idx.get(object_name, 0)  # 0 for unknown\n",
    "        embedding = self.embedding_layer(torch.tensor([obj_idx]))\n",
    "        \n",
    "        if as_tensor:\n",
    "            return embedding.squeeze(0)  # Return as tensor for training\n",
    "        else:\n",
    "            return embedding.squeeze(0).detach().cpu().numpy()  # Return as numpy for env\n",
    "    \n",
    "    def get_all_embeddings(self):\n",
    "        \"\"\"Get all embeddings for analysis\"\"\"\n",
    "        return self.embedding_layer.weight.detach().cpu().numpy()\n",
    "    \n",
    "    def visualize_embeddings(self, step=0):\n",
    "        \"\"\"Visualize learned embeddings\"\"\"\n",
    "        try:\n",
    "            import matplotlib.pyplot as plt\n",
    "            from sklearn.manifold import TSNE\n",
    "            \n",
    "            embeddings = self.get_all_embeddings()\n",
    "            object_names = ['unknown'] + self.known_objects\n",
    "            \n",
    "            # Use T-SNE for dimensionality reduction\n",
    "            tsne = TSNE(n_components=2, random_state=42, perplexity=min(5, len(embeddings)-1))\n",
    "            embeddings_2d = tsne.fit_transform(embeddings)\n",
    "            \n",
    "            plt.figure(figsize=(12, 10))\n",
    "            scatter = plt.scatter(embeddings_2d[:, 0], embeddings_2d[:, 1], alpha=0.7, s=100)\n",
    "            \n",
    "            # Add labels\n",
    "            for i, obj in enumerate(object_names):\n",
    "                plt.annotate(obj, (embeddings_2d[i, 0], embeddings_2d[i, 1]), \n",
    "                           xytext=(5, 5), textcoords='offset points', fontsize=8)\n",
    "            \n",
    "            plt.title(f'Learned Object Embeddings (Step {step})')\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(f'./learned_embeddings_step_{step}.png', dpi=300, bbox_inches='tight')\n",
    "            plt.close()\n",
    "            \n",
    "            print(f\"Learned embeddings visualization saved to './learned_embeddings_step_{step}.png'\")\n",
    "            \n",
    "        except ImportError:\n",
    "            print(\"Matplotlib or sklearn not available for embedding visualization\")\n",
    "\n",
    "class EmbeddingTrainingCallback(BaseCallback):\n",
    "    \"\"\"Callback to monitor embedding learning\"\"\"\n",
    "    \n",
    "    def __init__(self, check_interval=5000, verbose=0):\n",
    "        super().__init__(verbose)\n",
    "        self.check_interval = check_interval\n",
    "        self.embedding_history = {}\n",
    "    \n",
    "    def _on_step(self):\n",
    "        if self.n_calls % self.check_interval == 0:\n",
    "            # Log embedding statistics\n",
    "            if hasattr(self.model.policy, 'embedding_manager'):\n",
    "                embeddings = self.model.policy.embedding_manager.get_all_embeddings()\n",
    "                \n",
    "                # Calculate statistics\n",
    "                embedding_norms = np.linalg.norm(embeddings, axis=1)\n",
    "                embedding_std = np.std(embeddings, axis=0)\n",
    "                \n",
    "                self.logger.record(\"embeddings/mean_norm\", np.mean(embedding_norms))\n",
    "                self.logger.record(\"embeddings/std_norm\", np.std(embedding_norms))\n",
    "                self.logger.record(\"embeddings/max_norm\", np.max(embedding_norms))\n",
    "                self.logger.record(\"embeddings/min_norm\", np.min(embedding_norms))\n",
    "                \n",
    "                # Log some individual embedding dimensions\n",
    "                for i in range(min(4, embeddings.shape[1])):\n",
    "                    self.logger.record(f\"embeddings/dim_{i}_mean\", np.mean(embeddings[:, i]))\n",
    "                    self.logger.record(f\"embeddings/dim_{i}_std\", np.std(embeddings[:, i]))\n",
    "                \n",
    "                # Visualize embeddings every 50k steps\n",
    "                if self.n_calls % 50000 == 0:\n",
    "                    self.model.policy.embedding_manager.visualize_embeddings(step=self.n_calls)\n",
    "                    if mlflow.active_run():\n",
    "                        mlflow.log_artifact(f'./learned_embeddings_step_{self.n_calls}.png')\n",
    "        \n",
    "        return True\n",
    "\n",
    "class ImprovedTrainingCallback(BaseCallback):\n",
    "    \"\"\"Enhanced training callback with adaptive learning rate\"\"\"\n",
    "    def __init__(self, check_interval=1000, verbose=0):\n",
    "        super().__init__(verbose)\n",
    "        self.check_interval = check_interval\n",
    "        self.best_mean_reward = -np.inf\n",
    "        \n",
    "    def _on_step(self):\n",
    "        if self.n_calls % self.check_interval == 0:\n",
    "            mean_reward, std_reward = evaluate_policy(\n",
    "                self.model, \n",
    "                self.model.get_env(), \n",
    "                n_eval_episodes=5,\n",
    "                deterministic=False\n",
    "            )\n",
    "            \n",
    "            self.logger.record(\"eval/mean_reward\", mean_reward)\n",
    "            self.logger.record(\"eval/std_reward\", std_reward)\n",
    "            \n",
    "            # Adaptive learning rate\n",
    "            if mean_reward > self.best_mean_reward:\n",
    "                self.best_mean_reward = mean_reward\n",
    "            else:\n",
    "                current_lr = self.model.learning_rate\n",
    "                new_lr = current_lr * 0.99\n",
    "                self.model.learning_rate = new_lr\n",
    "            \n",
    "            # Early stopping for good performance\n",
    "            if mean_reward > 200:\n",
    "                return False\n",
    "                \n",
    "        return True\n",
    "\n",
    "class MLflowGradAndRewardCallback(BaseCallback):\n",
    "    \"\"\"Callback para logging en MLflow\"\"\"\n",
    "    def __init__(self, verbose=0):\n",
    "        super().__init__(verbose)\n",
    "        \n",
    "    def _on_step(self):\n",
    "        return True\n",
    "\n",
    "class ObjectAwareMlpLstmPolicy(nn.Module):\n",
    "    \"\"\"Custom policy that incorporates trainable object embeddings\"\"\"\n",
    "    \n",
    "    def __init__(self, observation_space, action_space, lr_schedule=None, \n",
    "                 net_arch=None, activation_fn=nn.ReLU, \n",
    "                 lstm_hidden_size=256, n_lstm_layers=1, \n",
    "                 enable_critic_lstm=True, **kwargs):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Extract dimensions\n",
    "        self.observation_space = observation_space\n",
    "        self.action_space = action_space\n",
    "        self.embedding_dim = 16\n",
    "        \n",
    "        # Object embedding manager\n",
    "        self.embedding_manager = TrainableObjectEmbeddingManager(embedding_dim=self.embedding_dim)\n",
    "        \n",
    "        # Policy network architecture\n",
    "        self.net_arch = net_arch or [64, 64]\n",
    "        self.activation_fn = activation_fn\n",
    "        \n",
    "        # Build feature extractor\n",
    "        self.feature_extractor = self._build_feature_extractor()\n",
    "        \n",
    "        # LSTM layer\n",
    "        self.lstm_hidden_size = lstm_hidden_size\n",
    "        self.n_lstm_layers = n_lstm_layers\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=self.net_arch[-1],\n",
    "            hidden_size=lstm_hidden_size,\n",
    "            num_layers=n_lstm_layers,\n",
    "            batch_first=True\n",
    "        )\n",
    "        \n",
    "        # Policy and value heads\n",
    "        self.policy_net = nn.Linear(lstm_hidden_size, action_space.shape[0])\n",
    "        self.value_net = nn.Linear(lstm_hidden_size, 1)\n",
    "        \n",
    "        # Initialize weights\n",
    "        self.apply(self._init_weights)\n",
    "        \n",
    "        print(f\"Initialized ObjectAwareMlpLstmPolicy with {observation_space.shape[0]} input dimensions\")\n",
    "    \n",
    "    def _build_feature_extractor(self):\n",
    "        \"\"\"Build the feature extraction network\"\"\"\n",
    "        layers = []\n",
    "        prev_size = self.observation_space.shape[0]\n",
    "        \n",
    "        for layer_size in self.net_arch:\n",
    "            layers.append(nn.Linear(prev_size, layer_size))\n",
    "            layers.append(self.activation_fn())\n",
    "            prev_size = layer_size\n",
    "        \n",
    "        return nn.Sequential(*layers)\n",
    "    \n",
    "    def _init_weights(self, module):\n",
    "        \"\"\"Initialize weights\"\"\"\n",
    "        if isinstance(module, nn.Linear):\n",
    "            torch.nn.init.orthogonal_(module.weight, gain=1.0)\n",
    "            if module.bias is not None:\n",
    "                module.bias.data.fill_(0.0)\n",
    "    \n",
    "    def forward(self, obs, lstm_states=None, episode_starts=None):\n",
    "        \"\"\"\n",
    "        Forward pass - embeddings are already included in observations\n",
    "        \"\"\"\n",
    "        batch_size = obs.shape[0] if len(obs.shape) > 1 else 1\n",
    "        \n",
    "        # Ensure obs is 2D\n",
    "        if len(obs.shape) == 1:\n",
    "            obs = obs.unsqueeze(0)\n",
    "        \n",
    "        # Feature extraction (embeddings already in observations)\n",
    "        features = self.feature_extractor(obs)\n",
    "        \n",
    "        # LSTM processing\n",
    "        if lstm_states is None:\n",
    "            lstm_states = self._init_lstm_states(batch_size, obs.device)\n",
    "        \n",
    "        # Reshape for LSTM (batch_size, seq_len=1, features)\n",
    "        features = features.unsqueeze(1)\n",
    "        lstm_out, lstm_states = self.lstm(features, lstm_states)\n",
    "        lstm_out = lstm_out.squeeze(1)  # Remove sequence dimension\n",
    "        \n",
    "        # Policy and value outputs\n",
    "        actions = self.policy_net(lstm_out)\n",
    "        values = self.value_net(lstm_out)\n",
    "        \n",
    "        return actions, values, lstm_states\n",
    "    \n",
    "    def _init_lstm_states(self, batch_size, device):\n",
    "        \"\"\"Initialize LSTM states\"\"\"\n",
    "        h = torch.zeros(self.n_lstm_layers, batch_size, self.lstm_hidden_size, device=device)\n",
    "        c = torch.zeros(self.n_lstm_layers, batch_size, self.lstm_hidden_size, device=device)\n",
    "        return (h, c)\n",
    "\n",
    "class MujocoEnvCNN(gym.Env):\n",
    "    \"\"\"Enhanced Mujoco environment for robotic grasping with trainable object embeddings\"\"\"\n",
    "    \n",
    "    def __init__(self, scene_path=None, movement_pattern='down', obs_shape=(300, 300, 3), num_frames=1000000, cfg=None):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Initialize variables\n",
    "        self.n_episodes = 0\n",
    "        self.force_mean = np.zeros(12)\n",
    "        self.force_std = np.ones(12)\n",
    "        self.force_count = 0\n",
    "        self.predicted_movement = None\n",
    "        self.num_agents = 1\n",
    "        self.scene_path = \"alarmclock_lift_s4_scene.xml\"\n",
    "        self.start_time = time.time()\n",
    "        self.experiment = 2\n",
    "        self.alpha = 0.1\n",
    "        self.contact_frames = 0\n",
    "        self.contact_frames_upward = 0\n",
    "        self.obs_shape = obs_shape\n",
    "        self.not_grabbed = True\n",
    "        self.total_module = 0\n",
    "        self.summed_total_module = 0\n",
    "        self.total_reward = 0\n",
    "        self.reward_success = cfg['reward_success']\n",
    "        self.penalty_invalid_point = cfg['penalization_out_of_bounds']\n",
    "        self.frame_idx = 1\n",
    "        self.x = 0.005\n",
    "        self.movement_pattern = movement_pattern\n",
    "        self.max_dist_tol = 0.11\n",
    "        self.frame_tol = 30\n",
    "        self.done = False\n",
    "        self.frame_counter = 0\n",
    "        self.num_frames = num_frames\n",
    "        self.max_hand_height = 0.30\n",
    "        self.scene_results = {}\n",
    "        self.contact_history = deque(maxlen=10)\n",
    "        self.force_history = deque(maxlen=5)\n",
    "        self.reward_history = deque(maxlen=20)\n",
    "        self.current_state = 0.0\n",
    "        self.std_state = 0.0\n",
    "        self.summary = \"\"\n",
    "        self.current_object_name = None\n",
    "        \n",
    "        # Trainable embedding manager\n",
    "        self.embedding_manager = TrainableObjectEmbeddingManager(embedding_dim=16)\n",
    "        \n",
    "        # Body parts definition\n",
    "        self.body_parts = {\n",
    "            \"ff_base\": 5, \"ff_proximal\": 6, \"ff_medial\": 7, \"ff_distal\": 8, \"ff_tip\": 9,\n",
    "            \"mf_base\": 10, \"mf_proximal\": 11, \"mf_medial\": 12, \"mf_distal\": 13, \"mf_tip\": 14,\n",
    "            \"rf_base\": 15, \"rf_proximal\": 16, \"rf_medial\": 17, \"rf_distal\": 18, \"rf_tip\": 19,\n",
    "            \"th_base\": 20, \"th_proximal\": 21, \"th_medial\": 22, \"th_distal\": 23, \"th_tip\": 24\n",
    "        }\n",
    "\n",
    "        # Load scene\n",
    "        gesture, sub, _ = extract_s_pattern(self.scene_path)\n",
    "        objeto = gesture.split('_')[0]\n",
    "        self.objeto = objeto\n",
    "        objeto_stl = check_object[objeto.replace('_', '')]\n",
    "        model_path = \"/home/diego/TFM/models/scenes/\" + gesture + \"_\" + sub + \"_scene.xml\"\n",
    "        self.model = mujoco.MjModel.from_xml_path(model_path)\n",
    "        self.data = mujoco.MjData(self.model)\n",
    "        \n",
    "        # Initialize simulation\n",
    "        mujoco.mj_forward(self.model, self.data)\n",
    "        for _ in range(20):\n",
    "            mujoco.mj_forward(self.model, self.data)\n",
    "\n",
    "        # Joint and body IDs\n",
    "        hand_joint_names = [\n",
    "            \"ffj0\", \"ffj1\", \"ffj2\", \"ffj3\", \"mfj0\", \"mfj1\", \"mfj2\", \"mfj3\",\n",
    "            \"rfj0\", \"rfj1\", \"rfj2\", \"rfj3\", \"thj0\", \"thj1\", \"thj2\", \"thj3\",\n",
    "            \"supination\", \"wrist_flexion\"\n",
    "        ]\n",
    "        \n",
    "        self.hand_joint_indices = [\n",
    "            mujoco.mj_name2id(self.model, mujoco.mjtObj.mjOBJ_JOINT, name)\n",
    "            for name in hand_joint_names\n",
    "        ]\n",
    "\n",
    "        self.hand_id = mujoco.mj_name2id(self.model, mujoco.mjtObj.mjOBJ_BODY, \"hand_root\")\n",
    "        self.obj_id = mujoco.mj_name2id(self.model, mujoco.mjtObj.mjOBJ_BODY, objeto_stl.replace('.stl', '') + \"_mesh\")\n",
    "        self.ff_tip_id = mujoco.mj_name2id(self.model, mujoco.mjtObj.mjOBJ_BODY, \"ff_tip\")\n",
    "        self.mf_tip_id = mujoco.mj_name2id(self.model, mujoco.mjtObj.mjOBJ_BODY, \"mf_tip\")\n",
    "        self.rf_tip_id = mujoco.mj_name2id(self.model, mujoco.mjtObj.mjOBJ_BODY, \"rf_tip\")\n",
    "        self.th_tip_id = mujoco.mj_name2id(self.model, mujoco.mjtObj.mjOBJ_BODY, \"th_tip\")\n",
    "        self.mocap_id = mujoco.mj_name2id(self.model, mujoco.mjtObj.mjOBJ_BODY, \"hand_root_mocap\")\n",
    "\n",
    "        # Update observation space to include object embedding\n",
    "        original_obs_dim = 39\n",
    "        embedding_dim = 16\n",
    "        total_obs_dim = original_obs_dim + embedding_dim\n",
    "        \n",
    "        # Action and observation spaces\n",
    "        self.action_space = spaces.Box(\n",
    "            low=np.array([self.model.actuator_ctrlrange[i, 0] for i in range(self.model.nu)], dtype=np.float32),\n",
    "            high=np.array([self.model.actuator_ctrlrange[i, 1] for i in range(self.model.nu)], dtype=np.float32),\n",
    "            dtype=np.float32\n",
    "        )\n",
    "\n",
    "        self.observation_space = spaces.Box(\n",
    "            low=-np.inf,\n",
    "            high=np.inf,\n",
    "            shape=(total_obs_dim,),  # Updated to include embeddings\n",
    "            dtype=np.float32\n",
    "        )\n",
    "\n",
    "    def contact_hand(self):\n",
    "        \"\"\"Check if hand is in contact with object\"\"\"\n",
    "        for i in range(self.data.ncon):\n",
    "            contact = self.data.contact[i]\n",
    "            if ((contact.geom1 == self.hand_id and contact.geom2 == self.obj_id) or\n",
    "                (contact.geom2 == self.hand_id and contact.geom1 == self.obj_id)):\n",
    "                return True\n",
    "        return False\n",
    "\n",
    "    def get_fingertip_forces(self):\n",
    "        \"\"\"Get fingertip forces\"\"\"\n",
    "        force_vectors = []\n",
    "        fingertip_ids = [self.ff_tip_id, self.mf_tip_id, self.rf_tip_id, self.th_tip_id]\n",
    "        for tip_id in fingertip_ids:\n",
    "            tip_force = np.zeros(3)\n",
    "            for i in range(self.data.ncon):\n",
    "                contact = self.data.contact[i]\n",
    "                if ((contact.geom1 == tip_id and contact.geom2 == self.obj_id) or\n",
    "                    (contact.geom2 == tip_id and contact.geom1 == self.obj_id)):\n",
    "                    force = np.zeros(6)\n",
    "                    mujoco.mj_contactForce(self.model, self.data, i, force)\n",
    "                    tip_force += force[:3]\n",
    "            force_vectors.append(tip_force)\n",
    "        return np.array(force_vectors)\n",
    "\n",
    "    def force_z_projection(self):\n",
    "        \"\"\"Calculate force projection on Z-axis\"\"\"\n",
    "        fingertip_forces = self.get_fingertip_forces()\n",
    "        total_force = np.sum(fingertip_forces, axis=0)\n",
    "        z_projection = np.linalg.norm(total_force[2]) / (np.linalg.norm(total_force) + 1e-6)\n",
    "        return z_projection\n",
    "\n",
    "    def fingertip_contact(self):\n",
    "        \"\"\"Check fingertip contacts with object\"\"\"\n",
    "        fingertip_ids = [self.ff_tip_id, self.mf_tip_id, self.rf_tip_id, self.th_tip_id]\n",
    "        contact_dict = {tip_id: False for tip_id in fingertip_ids}\n",
    "        for tip_id in fingertip_ids:\n",
    "            for i in range(self.data.ncon):\n",
    "                contact = self.data.contact[i]\n",
    "                if ((contact.geom1 == tip_id and contact.geom2 == self.obj_id) or\n",
    "                    (contact.geom2 == tip_id and contact.geom1 == self.obj_id)):\n",
    "                    contact_dict[tip_id] = True\n",
    "                    break\n",
    "        return contact_dict\n",
    "\n",
    "    def reset(self, seed=None):\n",
    "        \"\"\"Enhanced reset with intelligent sampling and object tracking\"\"\"\n",
    "        super().reset(seed=seed)\n",
    "        self.n_episodes += 1\n",
    "        self.total_reward = 0\n",
    "        self.contact_frames = 0\n",
    "        self.contact_frames_upward = 0\n",
    "        self.start_time = time.time()\n",
    "        self.final_reward = 0\n",
    "        self.grasp_success = False\n",
    "        self.total_module = 0\n",
    "        self.summed_total_module = 0\n",
    "        self.done = False\n",
    "        self.frame_counter = 0\n",
    "        self.movement_pattern = 'down'\n",
    "        \n",
    "        # Intelligent scene sampling\n",
    "        scenes_dir = \"/home/diego/TFM/models/scenes/\"\n",
    "        all_scenes = os.listdir(scenes_dir)\n",
    "        \n",
    "        # Sample based on previous performance\n",
    "        if hasattr(self, 'scene_results') and len(self.scene_results) > 10:\n",
    "            scene_scores = list(self.scene_results.items())\n",
    "            scene_scores.sort(key=lambda x: x[1])\n",
    "            start_idx = len(scene_scores) // 4\n",
    "            end_idx = 3 * len(scene_scores) // 4\n",
    "            medium_difficulty = scene_scores[start_idx:end_idx]\n",
    "            \n",
    "            if medium_difficulty:\n",
    "                chosen_object = random.choice(medium_difficulty)[0]\n",
    "                matching_scenes = [s for s in all_scenes if chosen_object in s]\n",
    "                if matching_scenes:\n",
    "                    sampled_scene = random.choice(matching_scenes)\n",
    "                else:\n",
    "                    sampled_scene = random.choice(all_scenes)\n",
    "            else:\n",
    "                sampled_scene = random.choice(all_scenes)\n",
    "        else:\n",
    "            sampled_scene = random.choice(all_scenes)\n",
    "\n",
    "        # Load the sampled scene\n",
    "        print(sampled_scene)\n",
    "        gesture, sub, _ = extract_s_pattern(sampled_scene)\n",
    "        print(gesture)\n",
    "        objeto = gesture.split('_')[0]\n",
    "        self.objeto = objeto\n",
    "        self.current_object_name = objeto  # Store for embedding lookup\n",
    "        \n",
    "        objeto_stl = check_object[objeto.replace('_', '')]\n",
    "        model_path = \"/home/diego/TFM/models/scenes/\" + gesture + \"_\" + sub + \"_scene.xml\"\n",
    "        self.model = mujoco.MjModel.from_xml_path(model_path)\n",
    "        self.data = mujoco.MjData(self.model)\n",
    "        \n",
    "        # Reinitialize body IDs for new scene\n",
    "        self.hand_id = mujoco.mj_name2id(self.model, mujoco.mjtObj.mjOBJ_BODY, \"hand_root\")\n",
    "        self.obj_id = mujoco.mj_name2id(self.model, mujoco.mjtObj.mjOBJ_BODY, objeto_stl.replace('.stl', '') + \"_mesh\")\n",
    "        self.mocap_id = mujoco.mj_name2id(self.model, mujoco.mjtObj.mjOBJ_BODY, \"hand_root_mocap\")\n",
    "\n",
    "        self.frame_idx = 1\n",
    "        self.contact_history.clear()\n",
    "        self.force_history.clear()\n",
    "        self.reward_history.clear()\n",
    "        \n",
    "        info = {'reset': f\"resetting on scene {sampled_scene} with object {objeto}\"}\n",
    "        obs = self._get_obs()\n",
    "        return obs, info\n",
    "\n",
    "    def step(self, action):\n",
    "        \"\"\"Enhanced step function with improved movement logic\"\"\"\n",
    "        done = False\n",
    "        object_contact = False\n",
    "        \n",
    "        # Current positions\n",
    "        current_hand_pos = self.data.xpos[self.hand_id]\n",
    "        current_hand_height = current_hand_pos[2]\n",
    "        current_obj_pos = self.data.xpos[self.obj_id]\n",
    "        current_obj_height = current_obj_pos[2]\n",
    "        height_diff = abs(current_hand_height - current_obj_height)\n",
    "\n",
    "        # Movement logic\n",
    "        if self.movement_pattern == 'down':\n",
    "            if height_diff > self.max_dist_tol:\n",
    "                multiplier = (height_diff - self.max_dist_tol) ** 0.3\n",
    "                if multiplier < 0:\n",
    "                    multiplier = 0\n",
    "                self.data.mocap_pos[self.mocap_id] -= [0, 0, self.x * multiplier]\n",
    "            \n",
    "            if self.contact_hand() or height_diff < self.max_dist_tol:\n",
    "                self.movement_pattern = 'stand'\n",
    "\n",
    "        elif self.movement_pattern == 'stand':\n",
    "            self.frame_counter += 1\n",
    "            if height_diff > self.max_dist_tol:\n",
    "                self.movement_pattern = 'down'\n",
    "            if self.frame_counter > self.frame_tol:\n",
    "                self.movement_pattern = 'up'\n",
    "\n",
    "        elif self.movement_pattern == 'up':\n",
    "            self.grasp_success = self.get_grasp_success()\n",
    "            if current_hand_height > self.max_hand_height:\n",
    "                self.done = True\n",
    "                if self.grasp_success:\n",
    "                    self.final_reward = 1.0\n",
    "                    print(f\"[{self.objeto}] SUCCESS\")\n",
    "                else:\n",
    "                    contact_ratio = self.contact_frames / max(self.frame_idx, 1)\n",
    "                    self.final_reward = contact_ratio\n",
    "                    print(f\"[{self.objeto}] FAILURE - Contact ratio: {contact_ratio:.2f}\")\n",
    "                \n",
    "                self.scene_results[self.objeto] = self.final_reward\n",
    "            \n",
    "            self.data.mocap_pos[self.mocap_id] += [0, 0, self.x]\n",
    "\n",
    "        # Apply control actions\n",
    "        kp = 50.0\n",
    "        kv = 5.0\n",
    "        for i in range(len(self.hand_joint_indices)):\n",
    "            if i >= 16:\n",
    "                kp = 20.0\n",
    "                kv = 2.0\n",
    "                self.data.ctrl[i] = action[i]\n",
    "                continue\n",
    "            error = action[i] - self.data.qpos[i]\n",
    "            self.data.ctrl[i] = kp * error + kv * self.data.qvel[i]\n",
    "\n",
    "        # Calculate reward\n",
    "        reward = self.reward()\n",
    "\n",
    "        # Step simulation\n",
    "        mujoco.mj_step(self.model, self.data)\n",
    "        self.frame_idx += 1\n",
    "\n",
    "        if self.grasp_success:\n",
    "            self.contact_frames += 1\n",
    "\n",
    "        obs = self._get_obs()\n",
    "        truncated = False\n",
    "        info = {}\n",
    "\n",
    "        return obs, reward, self.done, truncated, info\n",
    "\n",
    "    def reward(self):\n",
    "        \"\"\"Enhanced reward function\"\"\"\n",
    "        reward = 0\n",
    "        \n",
    "        # Contact rewards\n",
    "        contact_dict = self.fingertip_contact()\n",
    "        thumb_contact = contact_dict[self.th_tip_id]\n",
    "        other_contacts = sum([contact_dict[self.ff_tip_id], \n",
    "                             contact_dict[self.mf_tip_id], \n",
    "                             contact_dict[self.rf_tip_id]])\n",
    "        \n",
    "        # Base contact reward\n",
    "        if thumb_contact and other_contacts >= 1:\n",
    "            reward += 0.1 * other_contacts\n",
    "        \n",
    "        # Force projection reward\n",
    "        force_projection = self.force_z_projection()\n",
    "        if force_projection > 0.1:\n",
    "            reward += 0.5 * force_projection\n",
    "        \n",
    "        # Grasp stability reward\n",
    "        if self.grasp_success:\n",
    "            reward += 0.2\n",
    "            if self.movement_pattern == 'up':\n",
    "                reward += 0.1\n",
    "        \n",
    "        # Height reward during lifting\n",
    "        if self.movement_pattern == 'up' and self.grasp_success:\n",
    "            current_height = self.data.xpos[self.hand_id][2]\n",
    "            height_reward = (current_height / self.max_hand_height) * 0.3\n",
    "            reward += height_reward\n",
    "        \n",
    "        # Penalties\n",
    "        joint_velocity_penalty = np.mean(np.abs(self.data.qvel[:15]))\n",
    "        reward -= 0.01 * joint_velocity_penalty\n",
    "        \n",
    "        time_penalty = -0.001 * self.frame_idx\n",
    "        reward += time_penalty\n",
    "        \n",
    "        self.total_reward += reward\n",
    "        return reward\n",
    "\n",
    "    def _get_obs(self):\n",
    "        \"\"\"Get observation vector with object embedding\"\"\"\n",
    "        # Get forces\n",
    "        forces = self.get_fingertip_forces().flatten()\n",
    "        \n",
    "        # Update normalization\n",
    "        self._update_force_stats(forces)\n",
    "        normalized_forces = (forces - self.force_mean) / (self.force_std + 1e-8)\n",
    "        \n",
    "        # Get positions and orientations\n",
    "        fingertip_positions = []\n",
    "        for tip_id in [self.ff_tip_id, self.mf_tip_id, self.rf_tip_id, self.th_tip_id]:\n",
    "            fingertip_positions.append(self.data.xpos[tip_id])\n",
    "        fingertip_positions = np.array(fingertip_positions).flatten()\n",
    "        \n",
    "        object_position = self.data.xpos[self.obj_id]\n",
    "        target_orientation = self.data.xquat[self.obj_id]\n",
    "        hand_orientation = self.data.xquat[self.hand_id]\n",
    "        hand_to_object_orientation = target_orientation - hand_orientation\n",
    "        \n",
    "        # Get object embedding\n",
    "        if self.current_object_name:\n",
    "            object_embedding = self.embedding_manager.get_embedding(self.current_object_name)\n",
    "        else:\n",
    "            object_embedding = np.zeros(16)\n",
    "        \n",
    "        # Combine observations with object embedding\n",
    "        combined = np.concatenate([\n",
    "            normalized_forces, \n",
    "            fingertip_positions, \n",
    "            object_position, \n",
    "            target_orientation, \n",
    "            hand_orientation, \n",
    "            hand_to_object_orientation,\n",
    "            object_embedding  # Add object embedding\n",
    "        ])\n",
    "        \n",
    "        return combined.astype(np.float32)\n",
    "\n",
    "    def _update_force_stats(self, forces):\n",
    "        \"\"\"Update force normalization statistics\"\"\"\n",
    "        self.force_count += 1\n",
    "        delta = forces - self.force_mean\n",
    "        self.force_mean += delta / self.force_count\n",
    "        delta2 = forces - self.force_mean\n",
    "        self.force_std += delta * delta2\n",
    "\n",
    "    def get_grasp_success(self):\n",
    "        \"\"\"Check if grasp is successful\"\"\"\n",
    "        return self._check_contact()\n",
    "\n",
    "    def _check_contact(self):\n",
    "        \"\"\"Check contact between fingers and object\"\"\"\n",
    "        thumb_flag = False\n",
    "        other_finger_flag = False\n",
    "        \n",
    "        for i in range(self.data.ncon):\n",
    "            contact = self.data.contact[i]\n",
    "            if (contact.geom1 == self.obj_id or contact.geom2 == self.obj_id):\n",
    "                other_geom = contact.geom2 if contact.geom1 == self.obj_id else contact.geom1\n",
    "                geom_name = mujoco.mj_id2name(self.model, mujoco.mjtObj.mjOBJ_GEOM, other_geom)\n",
    "                if geom_name:\n",
    "                    if 'th' in geom_name:\n",
    "                        thumb_flag = True\n",
    "                    elif any(finger in geom_name for finger in ['ff', 'mf', 'rf']):\n",
    "                        other_finger_flag = True\n",
    "        \n",
    "        return thumb_flag and other_finger_flag\n",
    "\n",
    "    def render(self, options=None):\n",
    "        \"\"\"Render environment\"\"\"\n",
    "        panoramic_view = get_camera_image(self.model, self.data, 'panoramic_view', \n",
    "                                        width=self.obs_shape[0], height=self.obs_shape[1], \n",
    "                                        options=options)\n",
    "        panoramic_view_bgr = cv2.cvtColor(panoramic_view, cv2.COLOR_RGB2BGR)\n",
    "        return None, panoramic_view_bgr\n",
    "\n",
    "    def check_current_state(self):\n",
    "        \"\"\"Check and log current training state\"\"\"\n",
    "        summary = \"[FINAL] === Current State Results ===\\n\"\n",
    "        for scene, reward in self.scene_results.items():\n",
    "            summary += f\"{scene}: {reward:.2f}\\n\"\n",
    "        \n",
    "        if self.scene_results:\n",
    "            self.current_state = np.mean(list(self.scene_results.values()))\n",
    "            self.std_state = np.std(list(self.scene_results.values()))\n",
    "        else:\n",
    "            self.current_state = 0\n",
    "            self.std_state = 0\n",
    "            \n",
    "        summary += f\"Average reward: {self.current_state:.2f}\\n\"\n",
    "        summary += f\"Std reward: {self.std_state:.2f}\\n\"\n",
    "        self.summary = summary\n",
    "        print(summary)\n",
    "\n",
    "    def get_embedding_manager(self):\n",
    "        \"\"\"Get the embedding manager for the policy\"\"\"\n",
    "        return self.embedding_manager\n",
    "\n",
    "def comprehensive_evaluation(model, env, n_episodes=20):\n",
    "    \"\"\"Comprehensive model evaluation\"\"\"\n",
    "    results = {\n",
    "        'success_rate': 0,\n",
    "        'avg_reward': 0,\n",
    "        'avg_steps': 0,\n",
    "        'object_performance': {},\n",
    "        'contact_quality': 0\n",
    "    }\n",
    "    \n",
    "    successful_episodes = 0\n",
    "    total_reward = 0\n",
    "    total_steps = 0\n",
    "    total_contact_quality = 0\n",
    "    \n",
    "    for episode in range(n_episodes):\n",
    "        obs, info = env.reset()\n",
    "        episode_reward = 0\n",
    "        steps = 0\n",
    "        max_contact_quality = 0\n",
    "        \n",
    "        while True:\n",
    "            action, _ = model.predict(obs, deterministic=True)\n",
    "            obs, reward, done, truncated, info = env.step(action)\n",
    "            \n",
    "            episode_reward += reward\n",
    "            steps += 1\n",
    "            \n",
    "            current_quality = env.force_z_projection() * sum(env.fingertip_contact().values())\n",
    "            max_contact_quality = max(max_contact_quality, current_quality)\n",
    "            \n",
    "            if done or truncated:\n",
    "                break\n",
    "        \n",
    "        total_reward += episode_reward\n",
    "        total_steps += steps\n",
    "        total_contact_quality += max_contact_quality\n",
    "        \n",
    "        if env.final_reward > 0.8:\n",
    "            successful_episodes += 1\n",
    "        \n",
    "        obj_name = env.objeto\n",
    "        if obj_name not in results['object_performance']:\n",
    "            results['object_performance'][obj_name] = []\n",
    "        results['object_performance'][obj_name].append(episode_reward)\n",
    "    \n",
    "    results['success_rate'] = successful_episodes / n_episodes\n",
    "    results['avg_reward'] = total_reward / n_episodes\n",
    "    results['avg_steps'] = total_steps / n_episodes\n",
    "    results['contact_quality'] = total_contact_quality / n_episodes\n",
    "    \n",
    "    return results\n",
    "\n",
    "def setup_adaptive_training():\n",
    "    \"\"\"Setup adaptive training configuration\"\"\"\n",
    "    config = {\n",
    "        'initial_lr': 3e-4,\n",
    "        'min_lr': 1e-6,\n",
    "        'lr_decay': 0.995,\n",
    "        'clip_range': 0.2,\n",
    "        'ent_coef': 0.01,\n",
    "        'batch_size': 128,\n",
    "        'n_steps': 2048\n",
    "    }\n",
    "    \n",
    "    # Load training history if exists\n",
    "    if os.path.exists(\"./training_history.json\"):\n",
    "        with open(\"./training_history.json\", \"r\") as f:\n",
    "            history = json.load(f)\n",
    "            if history.get('best_reward', 0) > 100:\n",
    "                config['ent_coef'] = 0.001\n",
    "                config['lr_decay'] = 0.999\n",
    "    \n",
    "    return config\n",
    "\n",
    "# Main execution\n",
    "if __name__ == \"__main__\":\n",
    "    # Load configuration\n",
    "    with open('config.yaml', 'r') as f:\n",
    "        cfg = yaml.safe_load(f)\n",
    "\n",
    "    # Object database\n",
    "    stl_objects = [\n",
    "        \"airplane.stl\", \"alarmclock.stl\", \"apple.stl\", \"banana.stl\", \"binoculars.stl\",\n",
    "        \"bowl.stl\", \"camera.stl\", \"phone.stl\", \"cubelarge.stl\", \"cubemedium.stl\",\n",
    "        \"cubesmall.stl\", \"cup.stl\", \"cylinderlarge.stl\", \"cylindermedium.stl\",\n",
    "        \"cylindersmall.stl\", \"doorknob.stl\", \"elephant.stl\", \"eyeglasses.stl\",\n",
    "        \"flashlight.stl\", \"flute.stl\", \"hammer.stl\", \"headphones.stl\",\n",
    "        \"knife.stl\", \"lightbulb.stl\", \"mouse.stl\", \"mug.stl\", \"pan.stl\", \"piggybank.stl\",\n",
    "        \"pscontroller.stl\", \"pyramidlarge.stl\", \"pyramidmedium.stl\", \"pyramidsmall.stl\",\n",
    "        \"rubberduck.stl\", \"scissors.stl\", \"spherelarge.stl\", \"spheremedium.stl\",\n",
    "        \"spheresmall.stl\", \"stanfordbunny.stl\", \"stapler.stl\", \"toothbrush.stl\",\n",
    "        \"toothpaste.stl\", \"toruslarge.stl\", \"torusmedium.stl\", \"torussmall.stl\",\n",
    "        \"train.stl\", \"utahteapot.stl\", \"waterbottle.stl\", \"wineglass.stl\", \"wristwatch.stl\",\n",
    "    ]\n",
    "\n",
    "    check_object = {}\n",
    "    for obj in stl_objects:\n",
    "        base_name = obj.replace('.stl', '')\n",
    "        check_object[base_name] = obj\n",
    "\n",
    "    # Create directories\n",
    "    os.makedirs(\"./checkpoints_rppo\", exist_ok=True)\n",
    "    os.makedirs(\"./videos_rppo\", exist_ok=True)\n",
    "    os.makedirs(\"./model_checkpoints\", exist_ok=True)\n",
    "\n",
    "    # Create environment with trainable embeddings\n",
    "    env = MujocoEnvCNN(cfg=cfg)\n",
    "    check_env(env)\n",
    "\n",
    "    # Setup callbacks\n",
    "    callback = MLflowGradAndRewardCallback()\n",
    "    improved_callback = ImprovedTrainingCallback()\n",
    "    embedding_callback = EmbeddingTrainingCallback()\n",
    "\n",
    "    # Try to load existing model\n",
    "    checkpoint_dir = \"./checkpoints_rppo\"\n",
    "    pattern = re.compile(r\"rppo_model_(\\d+)_reward_([-\\d\\.]+)\\.zip\")\n",
    "    checkpoints = []\n",
    "    \n",
    "    for fname in os.listdir(checkpoint_dir):\n",
    "        match = pattern.match(fname)\n",
    "        if match:\n",
    "            timesteps = int(match.group(1))\n",
    "            reward = float(match.group(2))\n",
    "            checkpoints.append((fname, timesteps, reward))\n",
    "\n",
    "    if checkpoints:\n",
    "        best_checkpoint = max(checkpoints, key=lambda x: x[2])\n",
    "        best_fname, best_timesteps, best_reward = best_checkpoint\n",
    "        best_model_path = os.path.join(checkpoint_dir, best_fname)\n",
    "        \n",
    "        try:\n",
    "            # Try to load the model with the new environment\n",
    "            model = RecurrentPPO.load(best_model_path, env=env)\n",
    "            print(f\"Loaded best model: {best_fname} with reward {best_reward}\")\n",
    "            current_timesteps = best_timesteps\n",
    "            \n",
    "            # Transfer embedding manager to policy if it exists\n",
    "            if hasattr(env, 'embedding_manager') and not hasattr(model.policy, 'embedding_manager'):\n",
    "                model.policy.embedding_manager = env.embedding_manager\n",
    "                print(\"Transferred embedding manager from environment to policy\")\n",
    "                \n",
    "        except (ValueError, RuntimeError) as e:\n",
    "            if \"Observation spaces do not match\" in str(e) or \"size mismatch\" in str(e):\n",
    "                print(f\"Model incompatible with new observation space. Starting fresh training.\")\n",
    "                print(f\"Reason: {e}\")\n",
    "                model = None\n",
    "                current_timesteps = 0\n",
    "            else:\n",
    "                raise e\n",
    "    else:\n",
    "        print(\"No checkpoints found. Starting training from scratch.\")\n",
    "        model = None\n",
    "        current_timesteps = 0\n",
    "\n",
    "    if model is None:\n",
    "        print(\"Starting training from scratch with trainable object embeddings\")\n",
    "        current_timesteps = 0\n",
    "        \n",
    "        # Enhanced policy configuration\n",
    "        policy_kwargs = dict(\n",
    "            net_arch=dict(\n",
    "                pi=[512, 256, 128],\n",
    "                vf=[512, 256, 128]\n",
    "            ),\n",
    "            activation_fn=nn.ReLU,\n",
    "            lstm_hidden_size=512,\n",
    "            n_lstm_layers=2,\n",
    "            enable_critic_lstm=True,\n",
    "            ortho_init=False,\n",
    "            share_features_extractor=False\n",
    "        )\n",
    "\n",
    "        # Create model\n",
    "        model = RecurrentPPO(\n",
    "            \"MlpLstmPolicy\",\n",
    "            env,\n",
    "            learning_rate=3e-4,\n",
    "            n_steps=2048,\n",
    "            batch_size=128,\n",
    "            n_epochs=10,\n",
    "            gamma=0.99,\n",
    "            gae_lambda=0.95,\n",
    "            clip_range=0.2,\n",
    "            clip_range_vf=0.2,\n",
    "            ent_coef=0.01,\n",
    "            vf_coef=0.5,\n",
    "            max_grad_norm=0.8,\n",
    "            tensorboard_log=\"./rppo_tensorboard_embeddings/\",\n",
    "            device='cuda' if torch.cuda.is_available() else 'cpu',\n",
    "            policy_kwargs=policy_kwargs,\n",
    "            verbose=1\n",
    "        )\n",
    "        \n",
    "        # Transfer embedding manager to policy\n",
    "        model.policy.embedding_manager = env.embedding_manager\n",
    "        print(\"Embedding manager transferred to policy for training\")\n",
    "\n",
    "    # Training phases\n",
    "    training_phases = [\n",
    "        {\"timesteps\": 100000, \"max_hand_height\": 0.3, \"objects\": \"simple\"},\n",
    "        {\"timesteps\": 200000, \"max_hand_height\": 0.4, \"objects\": \"medium\"},\n",
    "        {\"timesteps\": 300000, \"max_hand_height\": 0.5, \"objects\": \"complex\"}\n",
    "    ]\n",
    "\n",
    "    # Simple objects for phased training\n",
    "    simple_objects = [\"cubesmall\", \"spheresmall\", \"cylindersmall\", \"cubemedium\"]\n",
    "    medium_objects = [\"spheremedium\", \"cylindermedium\", \"apple\", \"banana\"]\n",
    "    \n",
    "    # Start MLflow\n",
    "    mlflow.start_run()\n",
    "    \n",
    "    # Training loop\n",
    "    total_timesteps = 1000000\n",
    "    checkpoint_interval = 5000\n",
    "    \n",
    "    current_phase = 0\n",
    "    total_trained = current_timesteps\n",
    "\n",
    "    while total_trained < total_timesteps and current_phase < len(training_phases):\n",
    "        phase = training_phases[current_phase]\n",
    "        print(f\"Starting phase {current_phase + 1}: {phase}\")\n",
    "        \n",
    "        # Configure environment for current phase\n",
    "        env.max_hand_height = phase[\"max_hand_height\"]\n",
    "        \n",
    "        if phase[\"objects\"] == \"simple\":\n",
    "            env.allowed_objects = simple_objects\n",
    "        elif phase[\"objects\"] == \"medium\":\n",
    "            env.allowed_objects = medium_objects\n",
    "        else:\n",
    "            env.allowed_objects = None\n",
    "\n",
    "        # Train in current phase\n",
    "        phase_timesteps = min(phase[\"timesteps\"], total_timesteps - total_trained)\n",
    "        \n",
    "        send_text(f\"Starting phase {current_phase + 1} with {phase_timesteps} timesteps\")\n",
    "        \n",
    "        model.learn(\n",
    "            total_timesteps=phase_timesteps,\n",
    "            callback=[callback, improved_callback, embedding_callback],\n",
    "            reset_num_timesteps=False\n",
    "        )\n",
    "        \n",
    "        total_trained += phase_timesteps\n",
    "        \n",
    "        # Evaluate and save\n",
    "        mean_reward, std_reward = evaluate_policy(model, env, n_eval_episodes=5)\n",
    "        env.check_current_state()\n",
    "        \n",
    "        # Save checkpoint\n",
    "        model.save(f\"./checkpoints_rppo/phase_{current_phase+1}_{total_trained}_reward_{mean_reward:.2f}.zip\")\n",
    "        \n",
    "        # Record video\n",
    "        record_final_video(model, env, f\"./videos_rppo/phase_{current_phase+1}_{total_trained}.mp4\")\n",
    "        \n",
    "        # Adaptive difficulty\n",
    "        if env.current_state > 0.85 and current_phase < len(training_phases) - 1:\n",
    "            print(f\"Progressing to next phase. Current success rate: {env.current_state:.2f}\")\n",
    "            current_phase += 1\n",
    "        elif env.current_state > 0.85:\n",
    "            env.max_hand_height += 0.02\n",
    "            print(f\"Increasing difficulty. New max height: {env.max_hand_height}\")\n",
    "        \n",
    "        send_text(f\"Phase {current_phase + 1} completed. Mean reward: {mean_reward:.2f}\")\n",
    "        send_text(env.summary)\n",
    "\n",
    "    # Final evaluation\n",
    "    print(\"Training completed. Running final evaluation...\")\n",
    "    final_results = comprehensive_evaluation(model, env, n_episodes=20)\n",
    "    print(\"Final Results:\", final_results)\n",
    "    \n",
    "    # Record final video\n",
    "    record_final_video(model, env, \"./videos_rppo/final_agent.mp4\")\n",
    "    \n",
    "    # Save final model\n",
    "    model.save(\"final_grasping_policy_rppo_with_embeddings\")\n",
    "    \n",
    "    # Visualize final embeddings\n",
    "    if hasattr(model.policy, 'embedding_manager'):\n",
    "        model.policy.embedding_manager.visualize_embeddings(step=total_timesteps)\n",
    "        mlflow.log_artifact(f'./learned_embeddings_step_{total_timesteps}.png')\n",
    "    \n",
    "    mlflow.end_run()\n",
    "    print(\"Training completed successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4f14e6c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.end_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7a06138",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
